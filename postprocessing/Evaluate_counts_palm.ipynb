{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tqdm import tqdm_notebook\n",
    "from tqdm.notebook import tqdm, tnrange\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from osgeo import gdal, ogr, osr, gdalconst\n",
    "import os, sys\n",
    "import glob\n",
    "import simplekml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "sys.path.insert(0, os.getcwd())\n",
    "\n",
    "\n",
    "from utils.plots import plot_heatmap\n",
    "import utils.gdal_processing as gp\n",
    "from utils.read_geoTiff import readHR\n",
    "from utils.data_reader import interpPatches\n",
    "\n",
    "\n",
    "p2ha = lambda x: (x*10)**2 /100**2\n",
    "\n",
    "\n",
    "\n",
    "def no_output(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        sysout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, \"w\")\n",
    "        func(*args, **kwargs)\n",
    "        sys.stdout = sysout\n",
    "    return wrapper\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def zonal_stats_old(FID, input_zone_polygon, input_value_raster, fn, is_return_numpoints = False, refband=1):\n",
    "\n",
    "    # Open data\n",
    "    raster = gdal.Open(input_value_raster)\n",
    "    shp = ogr.Open(input_zone_polygon)\n",
    "    lyr = shp.GetLayer()\n",
    "\n",
    "    # Get raster georeference info\n",
    "    transform = raster.GetGeoTransform()\n",
    "    xOrigin = transform[0]\n",
    "    yOrigin = transform[3]\n",
    "    pixelWidth = transform[1]\n",
    "    pixelHeight = transform[5]\n",
    "\n",
    "    # Reproject vector geometry to same projection as raster\n",
    "    sourceSR = lyr.GetSpatialRef()\n",
    "    targetSR = osr.SpatialReference()\n",
    "    targetSR.ImportFromWkt(raster.GetProjectionRef())\n",
    "    coordTrans = osr.CoordinateTransformation(sourceSR,targetSR)\n",
    "    feat = lyr.GetFeature(FID)\n",
    "    geom = feat.GetGeometryRef()\n",
    "    geom.Transform(coordTrans)\n",
    "\n",
    "    # Get extent of feat\n",
    "    geom = feat.GetGeometryRef()\n",
    "\n",
    "    if geom.GetGeometryName() == 'MULTIPOLYGON' :\n",
    "        count = 0\n",
    "        pointsX = []; pointsY = []\n",
    "        for polygon in geom:\n",
    "            geomInner = geom.GetGeometryRef(count)\n",
    "            ring = geomInner.GetGeometryRef(0)\n",
    "            numpoints = ring.GetPointCount()\n",
    "            for p in range(numpoints):\n",
    "                    lon, lat, z = ring.GetPoint(p)\n",
    "                    pointsX.append(lon)\n",
    "                    pointsY.append(lat)\n",
    "            count += 1\n",
    "    elif geom.GetGeometryName() == 'POLYGON':\n",
    "        ring = geom.GetGeometryRef(0)\n",
    "        numpoints = ring.GetPointCount()\n",
    "        pointsX = []; pointsY = []\n",
    "        for p in range(numpoints):\n",
    "                lon, lat, z = ring.GetPoint(p)\n",
    "                pointsX.append(lon)\n",
    "                pointsY.append(lat)\n",
    "    elif (geom.GetGeometryName() == 'LINESTRING'):\n",
    "        numpoints = geom.GetPointCount()\n",
    "        pointsX = []\n",
    "        pointsY = []\n",
    "        for p in range(numpoints):\n",
    "            lon, lat, z = geom.GetPoint(p)\n",
    "            pointsX.append(lon)\n",
    "            pointsY.append(lat)\n",
    "    else:\n",
    "        sys.exit(\"ERROR: Geometry needs to be either Polygon or Multipolygon\")\n",
    "\n",
    "    xmin = min(pointsX)\n",
    "    xmax = max(pointsX)\n",
    "    ymin = min(pointsY)\n",
    "    ymax = max(pointsY)\n",
    "\n",
    "    # Specify offset and rows and columns to read\n",
    "    xoff = int((xmin - xOrigin)/pixelWidth)\n",
    "    yoff = int((yOrigin - ymax)/pixelWidth)\n",
    "    if xoff < 0 or yoff < 0:\n",
    "        return np.nan\n",
    "    xcount = int((xmax - xmin)/pixelWidth)+1\n",
    "    ycount = int((ymax - ymin)/pixelWidth)+1\n",
    "\n",
    "    if is_return_numpoints:\n",
    "        # TODO check that all the points are inside the region of interest\n",
    "        return geom.GetPointCount()\n",
    "\n",
    "    # Create memory target raster\n",
    "    target_ds = gdal.GetDriverByName('MEM').Create('', xcount, ycount, 1, gdal.GDT_Byte)\n",
    "    target_ds.SetGeoTransform((\n",
    "        xmin, pixelWidth, 0,\n",
    "        ymax, 0, pixelHeight,\n",
    "    ))\n",
    "\n",
    "    # Create for target raster the same projection as for the value raster\n",
    "    raster_srs = osr.SpatialReference()\n",
    "    raster_srs.ImportFromWkt(raster.GetProjectionRef())\n",
    "    target_ds.SetProjection(raster_srs.ExportToWkt())\n",
    "\n",
    "    # Rasterize zone polygon to raster\n",
    "    gdal.RasterizeLayer(target_ds, [1], lyr, burn_values=[1])\n",
    "\n",
    "    # Read raster as arrays\n",
    "    banddataraster = raster.GetRasterBand(refband)\n",
    "    try:\n",
    "        dataraster = banddataraster.ReadAsArray(xoff, yoff, xcount, ycount).astype(np.float)\n",
    "    except AttributeError:\n",
    "        return np.nan\n",
    "    bandmask = target_ds.GetRasterBand(1)\n",
    "    datamask = bandmask.ReadAsArray(0, 0, xcount, ycount).astype(np.float)\n",
    "    print(datamask.mean())\n",
    "    clip = True\n",
    "    if clip:\n",
    "        dataraster = np.clip(dataraster,0.01,1e9)\n",
    "    if not np.any(datamask):\n",
    "        print('datamask empty')\n",
    "        return np.nan\n",
    "    # Mask zone of raster\n",
    "#     zoneraster = np.ma.masked_array(dataraster,  np.logical_not(datamask))\n",
    "    dataraster[np.logical_not(datamask)] = np.nan\n",
    "\n",
    "    # Calculate statistics of zonal raster\n",
    "    # return numpy.average(zoneraster),numpy.mean(zoneraster),numpy.median(zoneraster),numpy.std(zoneraster),numpy.var(zoneraster)\n",
    "    try:\n",
    "        return fn(dataraster)\n",
    "    except ValueError:\n",
    "        print('fix')\n",
    "        return np.nan\n",
    "    \n",
    "def loop_zonal_stats_update_old(input_zone_polygon, input_value_raster, fieldname, fn, is_update=True, refband=1, is_pos_only=False):\n",
    "\n",
    "    shp = ogr.Open(input_zone_polygon, update=1)\n",
    "    lyr = shp.GetLayer()\n",
    "    lyrdf =lyr.GetLayerDefn()\n",
    "\n",
    "    # TreeFieldName = 'TreePredAd1'\n",
    "    if is_update:\n",
    "        id_ = lyrdf.GetFieldIndex(fieldname)\n",
    "        if id_ == -1:\n",
    "            field_defn = ogr.FieldDefn(fieldname, ogr.OFTReal)\n",
    "            lyr.CreateField(field_defn)\n",
    "            id_ = lyrdf.GetFieldIndex(fieldname)\n",
    "        else:\n",
    "            print('Field {} already exists, may overwrite'.format(fieldname))\n",
    "    outVals = []\n",
    "    id_Name = lyrdf.GetFieldIndex('Name')\n",
    "    for FID in range(lyr.GetFeatureCount()):\n",
    "        feat = lyr.GetFeature(FID)\n",
    "        if feat is not None:\n",
    "            # compute sum\n",
    "            name_ = feat.GetField(id_Name)\n",
    "            if 'pos' in name_ or not is_pos_only:\n",
    "                meanValue = zonal_stats(FID, input_zone_polygon, input_value_raster, fn, refband=refband)\n",
    "                print(f' {meanValue:.2f} Trees in {name_}')\n",
    "\n",
    "            else:\n",
    "                meanValue = zonal_stats(FID, input_zone_polygon, input_value_raster, fn, is_return_numpoints=True, refband=refband)\n",
    "                print(f' {meanValue:.2f} Ref points in {name_}')\n",
    "            outVals.append(meanValue)\n",
    "            if np.isnan(meanValue):\n",
    "                print(meanValue,FID)\n",
    "            if is_update:\n",
    "                lyr.SetFeature(feat)\n",
    "                feat.SetField(id_,meanValue)\n",
    "                lyr.SetFeature(feat)\n",
    "    return np.sum(outVals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def loop_zonal_stats_update(input_zone_polygon, input_value_raster, fieldname, fn, is_update=True, refband=1, is_pos_only=False,bias=1, field_name = 'Name'):\n",
    "\n",
    "    shp = ogr.Open(input_zone_polygon, update=1)\n",
    "    lyr = shp.GetLayer()\n",
    "    lyrdf =lyr.GetLayerDefn()\n",
    "\n",
    "    \n",
    "    id_ = lyrdf.GetFieldIndex(fieldname)\n",
    "    if id_ == -1:\n",
    "        field_defn = ogr.FieldDefn(fieldname, ogr.OFTReal)\n",
    "        lyr.CreateField(field_defn)\n",
    "        id_ = lyrdf.GetFieldIndex(fieldname)\n",
    "    else:\n",
    "        print('Field {} already exists, may overwrite'.format(fieldname))\n",
    "    outVals = []\n",
    "    id_Name = lyrdf.GetFieldIndex(field_name)\n",
    "    for FID in range(lyr.GetFeatureCount()):\n",
    "        feat = lyr.GetFeature(FID)\n",
    "        if feat is not None:\n",
    "            # compute sum\n",
    "            name_ = feat.GetField(id_Name)\n",
    "            meanValue = zonal_stats(FID, input_zone_polygon, input_value_raster, fn, refband=refband,bias=bias)\n",
    "#             print(f' {meanValue:.2f} Trees in {name_}')\n",
    "            outVals.append(meanValue)\n",
    "#             if np.isnan(meanValue):\n",
    "#                 print(name_,FID,'is all nan')\n",
    "            lyr.SetFeature(feat)\n",
    "            feat.SetField(id_,meanValue)\n",
    "            lyr.SetFeature(feat)\n",
    "    return np.sum(outVals)\n",
    "\n",
    "def zonal_stats(FID, input_zone_polygon, input_value_raster, fn, is_return_numpoints = False, refband=1, bias = 1.0):\n",
    "\n",
    "    # Open data\n",
    "    raster = gdal.Open(input_value_raster)\n",
    "    shp = ogr.Open(input_zone_polygon)\n",
    "    lyr = shp.GetLayer()\n",
    "\n",
    "    # Get raster georeference info\n",
    "    transform = raster.GetGeoTransform()\n",
    "    xOrigin = transform[0]\n",
    "    yOrigin = transform[3]\n",
    "    pixelWidth = transform[1]\n",
    "    pixelHeight = transform[5]\n",
    "\n",
    "    # Reproject vector geometry to same projection as raster\n",
    "    sourceSR = lyr.GetSpatialRef()\n",
    "    targetSR = osr.SpatialReference()\n",
    "    targetSR.ImportFromWkt(raster.GetProjectionRef())\n",
    "    coordTrans = osr.CoordinateTransformation(sourceSR,targetSR)\n",
    "    feat = lyr.GetFeature(FID)\n",
    "    geom = feat.GetGeometryRef()\n",
    "    geom.Transform(coordTrans)\n",
    "\n",
    "    # Get extent of feat\n",
    "    geom = feat.GetGeometryRef()\n",
    "    if (geom.GetGeometryName() == 'MULTIPOLYGON'):\n",
    "        count = 0\n",
    "        pointsX = []; pointsY = []\n",
    "        for polygon in geom:\n",
    "            geomInner = geom.GetGeometryRef(count)\n",
    "            ring = geomInner.GetGeometryRef(0)\n",
    "            numpoints = ring.GetPointCount()\n",
    "            for p in range(numpoints):\n",
    "                    lon, lat, z = ring.GetPoint(p)\n",
    "                    pointsX.append(lon)\n",
    "                    pointsY.append(lat)\n",
    "            count += 1\n",
    "    elif geom.GetGeometryName() == 'POLYGON':\n",
    "        ring = geom.GetGeometryRef(0)\n",
    "        numpoints = ring.GetPointCount()\n",
    "        pointsX = []; pointsY = []\n",
    "        for p in range(numpoints):\n",
    "                lon, lat, z = ring.GetPoint(p)\n",
    "                pointsX.append(lon)\n",
    "                pointsY.append(lat)\n",
    "    else:\n",
    "        sys.exit(\"ERROR: Geometry needs to be a Polygon\")\n",
    "    xmin = min(pointsX)\n",
    "    xmax = max(pointsX)\n",
    "    ymin = min(pointsY)\n",
    "    ymax = max(pointsY)\n",
    "\n",
    "    # Specify offset and rows and columns to read\n",
    "    xoff = int((xmin - xOrigin)/pixelWidth)\n",
    "    yoff = int((yOrigin - ymax)/pixelWidth)\n",
    "   \n",
    "    xcount = int((xmax - xmin)/pixelWidth)+1\n",
    "    ycount = int((ymax - ymin)/pixelWidth)+1\n",
    "\n",
    "\n",
    "    xoff = min(xoff,raster.RasterXSize -1)\n",
    "    xoff = max(xoff,1)\n",
    "    \n",
    "    xcount = min(xcount,raster.RasterXSize -1 - xoff)\n",
    "    ycount = min(ycount,raster.RasterYSize -1 - yoff)\n",
    "      \n",
    "\n",
    "    # Create memory target raster\n",
    "    target_ds = gdal.GetDriverByName('MEM').Create('', xcount, ycount, 1, gdal.GDT_Byte)\n",
    "    target_ds.SetGeoTransform((\n",
    "        xmin, pixelWidth, 0,\n",
    "        ymax, 0, pixelHeight,\n",
    "    ))\n",
    "\n",
    "    # Create for target raster the same projection as for the value raster\n",
    "    raster_srs = osr.SpatialReference()\n",
    "    raster_srs.ImportFromWkt(raster.GetProjectionRef())\n",
    "    target_ds.SetProjection(raster_srs.ExportToWkt())\n",
    "\n",
    "    # Rasterize zone polygon to raster\n",
    "    gdal.RasterizeLayer(target_ds, [1], lyr, burn_values=[1])\n",
    "\n",
    "    # Read raster as arrays\n",
    "    banddataraster = raster.GetRasterBand(refband)\n",
    "    try:\n",
    "        dataraster = banddataraster.ReadAsArray(xoff, yoff, xcount, ycount).astype(np.float)\n",
    "    except AttributeError:\n",
    "        print('dataraster wrong')\n",
    "#         print('geotransform',transform)\n",
    "        print(xoff,yoff,xcount,ycount)\n",
    "        print(raster.RasterXSize,raster.RasterYSize, 'xmax,ymax:',xoff+xcount,yoff+xcount)\n",
    "        return np.nan\n",
    "    \n",
    "    bandmask = target_ds.GetRasterBand(1)\n",
    "    datamask = bandmask.ReadAsArray(0, 0, xcount, ycount).astype(np.float)\n",
    "#     print(datamask.mean())\n",
    "    clip = True\n",
    "    if clip:\n",
    "#         dataraster = np.clip(dataraster,0.01,1e9)\n",
    "        dataraster[dataraster < 0.01] = np.nan\n",
    "    dataraster[dataraster == 99] = np.nan\n",
    "    \n",
    "    if not np.any(datamask):\n",
    "        print('datamask empty')\n",
    "        return np.nan\n",
    "    # Mask zone of raster\n",
    "#     zoneraster = np.ma.masked_array(dataraster,  np.logical_not(datamask))\n",
    "    dataraster[np.logical_not(datamask)] = np.nan\n",
    "    dataraster *=bias\n",
    "    # Calculate statistics of zonal raster\n",
    "    # return numpy.average(zoneraster),numpy.mean(zoneraster),numpy.median(zoneraster),numpy.std(zoneraster),numpy.var(zoneraster)\n",
    "    try:\n",
    "        return fn(dataraster)\n",
    "    except ValueError:\n",
    "        print('fix')\n",
    "        return np.nan\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj='palm'\n",
    "\n",
    "object_dict= {'palm':0,'coco':1}\n",
    "\n",
    "# ref_band = object_dict[obj]\n",
    "\n",
    "# points ='/home/pf/pfstud/andresro/tree_annotationsAug2019/annotations/Jan/palm/49MCV/Palm_Jan_1.kml'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for automatic GT\n",
    "data_config = {'T47NQA':'101.45,0.53,101.62,0.55'} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median_sentinel2(path, ref_tile, roi_lon_lat=None, resolution=60):\n",
    "    list1 = glob.glob(path+'/*{}*'.format(ref_tile))\n",
    "    list2 = [glob.glob(f\"{x}/GRANULE/*/IMG_DATA/R{resolution}m/*_TCI_{resolution}m.jp2\") for x in list1]\n",
    "    \n",
    "    medians = []\n",
    "    masks = []\n",
    "\n",
    "    for count, id_ in enumerate(list2):\n",
    "        if len(id_) > 0:\n",
    "            \n",
    "            #ds = gdal.Open(id_[0])\n",
    "            #array = ds.ReadAsArray()\n",
    "            #array = array.transpose().swapaxes(0, 1)\n",
    "            array = readHR(roi_lon_lat,data_file=id_[0],scale=10,as_float=False, is_verbose=False, is_assert_blank=False)\n",
    "\n",
    "#            print(count, id_[0].split('/')[-6])\n",
    "\n",
    "            mask_ = (array == 0).all(axis=-1)\n",
    "\n",
    "            medians.append(array)\n",
    "            try:\n",
    "                if resolution == 10:\n",
    "                    resolution_ = 20\n",
    "                else:\n",
    "                    resolution_ = resolution\n",
    "                id_scl = id_[0].replace(f'TCI_{resolution}m',f'SCL_{resolution_}m')\n",
    "                id_scl = id_scl.replace(f'/R{resolution}m/',f'/R{resolution_}m/')\n",
    "                \n",
    "                #ds = gdal.Open(id_[0].replace('TCI_60m','SCL_60m'))\n",
    "                arrayscl = readHR(roi_lon_lat,data_file=id_scl,scale=resolution_,as_float=False,is_assert_blank=False, is_verbose=False)\n",
    "                arrayscl = interpPatches(arrayscl, array.shape[0:2], squeeze=True, mode='edge').squeeze()\n",
    "                #arrayscl = ds.ReadAsArray()\n",
    "                #arrayscl = arrayscl.transpose().swapaxes(0, 1)\n",
    "                mask_ = np.logical_or(mask_, arrayscl==3)\n",
    "                mask_ = np.logical_or(mask_, arrayscl == 11)\n",
    "                mask_ = np.logical_or(mask_, arrayscl == 6)\n",
    "\n",
    "\n",
    "                id_cld = glob.glob(id_[0].split('/IMG_DATA/')[0]+f'/QI_DATA/*CLD*{resolution_}m.jp2')[0]\n",
    "                array_cld = readHR(roi_lon_lat,data_file=id_cld,scale=resolution_,as_float=False, is_verbose=False, is_assert_blank=False)\n",
    "                array_cld = interpPatches(array_cld, array.shape[0:2], squeeze=True, mode='edge').squeeze()\n",
    "\n",
    "                #array_cld = ds.ReadAsArray()\n",
    "                #array_cld = array_cld.transpose().swapaxes(0, 1)\n",
    "                mask_ = np.logical_or(mask_, array_cld > 5)\n",
    "            except IndexError:\n",
    "                print('error in cld, or SCL',count)\n",
    "\n",
    "            mask_ = np.repeat(mask_[...,np.newaxis], 3, axis=-1)\n",
    "            masks.append(mask_)\n",
    "\n",
    "\n",
    "\n",
    "    mask_ = np.stack(masks)\n",
    "    median_ = np.ma.masked_array(np.stack(medians), mask_)\n",
    "    median_ = np.ma.median(median_,axis=0) /255.0\n",
    "    \n",
    "    return median_\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2ha = lambda x: (x/10)**2\n",
    "\n",
    "\n",
    "# @no_output\n",
    "def get_rasters(folder_inference, tile, folder_annotations, group='group1', preds_axis=0, sq_kernel=2, scale=10, clip_min=0.2):\n",
    "    ds_out = pd.DataFrame(columns=['GT','Pred','lon','lat'])\n",
    "    \n",
    "    ref_folder = f'{folder_annotations}/{tile}/{group}'\n",
    "    if not os.path.isdir(ref_folder):\n",
    "        print(ref_folder,'does not exist')\n",
    "        return None\n",
    "\n",
    "\n",
    "    group = ref_folder.split('/')[-1]\n",
    "        \n",
    "    ref_raster = glob.glob(f'{folder_inference}/{tile}*_preds_reg*.tif')\n",
    "    \n",
    "    if len(ref_raster) == 0:\n",
    "        print(f' no files found in {folder_inference}/{tile}*_preds_reg*.tif skipping...')\n",
    "        return None\n",
    "\n",
    "    assert len(ref_raster) == 1,len(ref_raster)\n",
    "    ref_raster = ref_raster[0]\n",
    "\n",
    "    ds = gdal.Open(ref_raster)\n",
    "    roi_ = gp.get_positive_area_folder(ref_folder)\n",
    "\n",
    "    lims = gp.to_xy_box(roi_, ds, enlarge=10)\n",
    "\n",
    "    gt = gp.rasterize_points_pos_neg_folder(folder=ref_folder,refDataset=ref_raster,lims=lims,lims_with_labels=lims,sq_kernel=sq_kernel)\n",
    "    gt[gt == -1] = np.nan\n",
    "\n",
    "    preds = readHR(data_file=ref_raster,roi_lon_lat=roi_,scale=10, as_float=False, is_assert_blank=False)\n",
    "    #sys.stdout = sys.__stdout__\n",
    "    if preds.shape[-1] == 2:\n",
    "        preds = preds[...,preds_axis]\n",
    "#             preds[preds <clip_min] = 0\n",
    "#     preds[preds==99] = np.nan\n",
    "#     preds = np.clip(preds*1.3,0,2.5)\n",
    "\n",
    "    ref_raster_sem = ref_raster.replace('reg.tif','semA.tif')\n",
    "\n",
    "#     if os.path.isfile(ref_raster_sem):\n",
    "#         preds_sem = readHR(data_file=ref_raster.replace('reg.tif','semA.tif'),roi_lon_lat=roi_,scale=10, as_float=False, is_assert_blank=False)\n",
    "#     else:\n",
    "#         preds_sem = preds > 0.5\n",
    "\n",
    "# #             ds, fig = plot_preds(scale,gt,preds, tile, group)\n",
    "#             ds['lon'] = (roi_[0]+roi_[2])/2\n",
    "#             ds['lat'] = (roi_[1]+roi_[3])/2\n",
    "#             ds_out = ds_out.append(ds)\n",
    "    return {'gt':gt,\n",
    "           'preds':preds,\n",
    "           'roi_':roi_}\n",
    "    \n",
    "    \n",
    "def plot_preds(scale,raster,preds, tile, group,density = (0,3)):\n",
    "    dens_min,dens_max = density\n",
    "    mask_out = np.isnan(raster) | np.isnan(preds)\n",
    "#         gt_count = raster[~mask_out].sum()\n",
    "    preds1 = preds.copy()\n",
    "    preds1[mask_out] = np.nan\n",
    "    raster1 = raster.copy()\n",
    "    raster1[mask_out] = np.nan\n",
    "\n",
    "    print(p2ha(scale))\n",
    "    r1 = gp.block_reduce(raster1,(scale,scale),np.nansum)\n",
    "    p1 = gp.block_reduce(preds1,(scale,scale),np.nansum)\n",
    "    diff = p1  - r1\n",
    "    diff1 = (p1 - r1 )/ r1\n",
    "    diff1[np.logical_and(r1 == 0, p1 == 0) ] = 0\n",
    "    diff1[np.logical_and(r1 == 0, p1 > 0) ] = np.nan\n",
    "\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    n_col = 3\n",
    "    gs = gridspec.GridSpec(nrows=1,ncols=n_col,left=0.02, bottom=0.06, right=0.95, top=0.94, wspace=0.1, figure=fig)\n",
    "\n",
    "    txt = f' {tile} {group} {p2ha(scale)}ha'\n",
    "    \n",
    "    # GT\n",
    "    # ax = plt.subplot(gs[0])\n",
    "    ax = fig.add_subplot(gs[0])\n",
    "\n",
    "    im = ax.imshow(raster,vmin=dens_min,vmax=dens_max)\n",
    "    \n",
    "    cbar = fig.colorbar(im,ax=ax,orientation='horizontal')\n",
    "    cbar.ax.set_xlabel(f'Trees/ {p2ha(1):.2f}ha blocks')\n",
    "    ax.set_title(f'Trees GT {np.nansum(raster1):.2f}') # ' ({np.nanmax(raster):.2f})')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(f' {preds1.shape[0]/100:.2f}km')\n",
    "    ax.set_ylabel(f' {preds1.shape[1]/100:.2f}km')\n",
    "\n",
    "    # PREDS\n",
    "#    ax = plt.subplot(gs[1])\n",
    "    ax = fig.add_subplot(gs[1])\n",
    "\n",
    "    im = ax.imshow(preds,vmin=dens_min,vmax=dens_max)\n",
    "    cbar = fig.colorbar(im,ax=ax,orientation='horizontal')\n",
    "    cbar.ax.set_xlabel(f'Trees/ {p2ha(1):.2f}ha blocks')\n",
    "    ax.set_title(f'Trees Pred {np.nansum(preds1):.2f}') #' ({np.nanmax(preds):.2f})')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(f' {preds1.shape[0]/100:.2f}km')#  \\n\\n'+txt)\n",
    "    ax.set_ylabel(f' {preds1.shape[1]/100:.2f}km')\n",
    "\n",
    "    # DIFSS\n",
    "#    ax = plt.subplot(gs[2])\n",
    "    ax = fig.add_subplot(gs[2])\n",
    "\n",
    "    lim_ = dens_max * ((scale/2)**2)\n",
    "    im = ax.imshow(diff,cmap = 'bwr', vmin = -lim_,vmax=lim_ ) #,vmin=-dens_max*scale*3,vmax=dens_max*scale*3)\n",
    "    cbar = fig.colorbar(im,ax=ax,orientation='horizontal')\n",
    "    cbar.ax.set_xlabel(f'Trees/ {p2ha(scale)}ha blocks')\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax.set_title(f'Error per {p2ha(scale)}ha blocks')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "\n",
    "    \n",
    "#     fig.suptitle(f' {tile} {group} {p2ha(scale)}ha', y=1.01)\n",
    "#     fig.text(.5, .06, txt, ha='center')\n",
    "\n",
    "\n",
    "    # Scatter\n",
    "    zeros_ = np.logical_and(p1== 0,r1==0).ravel()\n",
    "    ds = pd.DataFrame({'GT':r1.ravel(),'Pred':p1.ravel()})\n",
    "    return ds,fig\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2ha = lambda x: (x/10)**2\n",
    "\n",
    "def plot_preds(scale,raster,preds, tile, group,density = (0,3)):\n",
    "    dens_min,dens_max = density\n",
    "    mask_out = np.isnan(raster) | np.isnan(preds)\n",
    "#         gt_count = raster[~mask_out].sum()\n",
    "    preds1 = preds.copy()\n",
    "    preds1[mask_out] = np.nan\n",
    "    raster1 = raster.copy()\n",
    "    raster1[mask_out] = np.nan\n",
    "\n",
    "    print(p2ha(scale))\n",
    "    r1 = gp.block_reduce(raster1,(scale,scale),np.nansum)\n",
    "    p1 = gp.block_reduce(preds1,(scale,scale),np.nansum)\n",
    "    diff = p1  - r1\n",
    "    diff1 = (p1 - r1 )/ r1\n",
    "    diff1[np.logical_and(r1 == 0, p1 == 0) ] = 0\n",
    "    diff1[np.logical_and(r1 == 0, p1 > 0) ] = np.nan\n",
    "\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    n_col = 3\n",
    "    gs = gridspec.GridSpec(nrows=1,ncols=n_col,left=0.02, bottom=0.06, right=0.95, top=0.94, wspace=0.1, figure=fig)\n",
    "\n",
    "    txt = f' {tile} {group} {p2ha(scale)}ha'\n",
    "    \n",
    "    # GT\n",
    "    # ax = plt.subplot(gs[0])\n",
    "    ax = fig.add_subplot(gs[0])\n",
    "\n",
    "    im = ax.imshow(raster,vmin=dens_min,vmax=dens_max)\n",
    "    \n",
    "    cbar = fig.colorbar(im,ax=ax,orientation='horizontal')\n",
    "    cbar.ax.set_xlabel(f'Trees/ {p2ha(1):.2f}ha blocks')\n",
    "    ax.set_title(f'Trees GT {np.nansum(raster1):.2f}') # ' ({np.nanmax(raster):.2f})')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(f' {preds1.shape[0]/100:.2f}km')\n",
    "    ax.set_ylabel(f' {preds1.shape[1]/100:.2f}km')\n",
    "\n",
    "    # PREDS\n",
    "#    ax = plt.subplot(gs[1])\n",
    "    ax = fig.add_subplot(gs[1])\n",
    "\n",
    "    im = ax.imshow(preds,vmin=dens_min,vmax=dens_max)\n",
    "    cbar = fig.colorbar(im,ax=ax,orientation='horizontal')\n",
    "    cbar.ax.set_xlabel(f'Trees/ {p2ha(1):.2f}ha blocks')\n",
    "    ax.set_title(f'Trees Pred {np.nansum(preds1):.2f}') #' ({np.nanmax(preds):.2f})')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(f' {preds1.shape[0]/100:.2f}km')#  \\n\\n'+txt)\n",
    "    ax.set_ylabel(f' {preds1.shape[1]/100:.2f}km')\n",
    "\n",
    "    # DIFSS\n",
    "#    ax = plt.subplot(gs[2])\n",
    "    ax = fig.add_subplot(gs[2])\n",
    "\n",
    "    lim_ = dens_max * ((scale/2)**2)\n",
    "    im = ax.imshow(diff,cmap = 'bwr', vmin = -lim_,vmax=lim_ ) #,vmin=-dens_max*scale*3,vmax=dens_max*scale*3)\n",
    "    cbar = fig.colorbar(im,ax=ax,orientation='horizontal')\n",
    "    cbar.ax.set_xlabel(f'Trees/ {p2ha(scale)}ha blocks')\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax.set_title(f'Error per {p2ha(scale)}ha blocks')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "\n",
    "    \n",
    "#     fig.suptitle(f' {tile} {group} {p2ha(scale)}ha', y=1.01)\n",
    "#     fig.text(.5, .06, txt, ha='center')\n",
    "\n",
    "\n",
    "    # Scatter\n",
    "    zeros_ = np.logical_and(p1== 0,r1==0).ravel()\n",
    "    ds = pd.DataFrame({'GT':r1.ravel(),'Pred':p1.ravel()})\n",
    "    return ds,fig\n",
    "\n",
    "\n",
    "#Â @no_output\n",
    "def plot_counts(folder_inference, tile, folder_annotations, group='group1', preds_axis=0, sq_kernel=2, scale=10, clip_min=0.2):\n",
    "    ds_out = pd.DataFrame(columns=['GT','Pred','lon','lat'])\n",
    "    \n",
    "    ref_folders = glob.glob(f'{folder_annotations}/{tile}/{group}')\n",
    "    if not ref_folders:\n",
    "        print(f'no folders in {folder_annotations}/{tile}/{group}')\n",
    "        return ds_out\n",
    "\n",
    "    is_aut_gt = False\n",
    "    for ref_folder in ref_folders:\n",
    "        group = ref_folder.split('/')[-1]\n",
    "        print(ref_folder, group)\n",
    "        ref_raster = glob.glob(f'{folder_inference}/{tile}*_preds_reg*.tif')\n",
    "        if len(ref_raster) == 0:\n",
    "            print(f' no files found in {folder_inference}/{tile}*_preds_reg*.tif skipping...')\n",
    "            fig = None\n",
    "        else:\n",
    "            ref_raster = ref_raster[0]\n",
    "            #sys.stdout = open(os.devnull, \"w\")\n",
    "\n",
    "            ds = gdal.Open(ref_raster)\n",
    "            if is_aut_gt:\n",
    "                return None\n",
    "                roi_ = data_config[tile]\n",
    "            else:\n",
    "                roi_ = gp.get_positive_area_folder(ref_folder)\n",
    "            lims = gp.to_xy_box(roi_, ds, enlarge=10)\n",
    "\n",
    "            if is_aut_gt:\n",
    "                raster = gp.rasterize_points_constrained(Input=ref_folder,refDataset=ref_raster,lims=lims,lims_with_labels=lims,sq_kernel=sq_kernel)\n",
    "            else:\n",
    "                raster = gp.rasterize_points_pos_neg_folder(folder=ref_folder,refDataset=ref_raster,lims=lims,lims_with_labels=lims,sq_kernel=sq_kernel)\n",
    "            raster[raster == -1] = np.nan\n",
    "\n",
    "            preds = readHR(data_file=ref_raster,roi_lon_lat=roi_,scale=10, as_float=False, is_assert_blank=False)\n",
    "            #sys.stdout = sys.__stdout__\n",
    "            if preds.shape[-1] == 2:\n",
    "                preds = preds[...,preds_axis]\n",
    "            preds[preds <clip_min] = 0\n",
    "            preds[preds==99] = np.nan\n",
    "        #     preds = np.clip(preds*1.3,0,2.5)\n",
    "\n",
    "            ref_raster_sem = ref_raster.replace('reg.tif','semA.tif')\n",
    "\n",
    "            if os.path.isfile(ref_raster_sem):\n",
    "                preds_sem = readHR(data_file=ref_raster.replace('reg.tif','semA.tif'),roi_lon_lat=roi_,scale=10, as_float=False, is_assert_blank=False)\n",
    "            else:\n",
    "                preds_sem = preds > 0.5\n",
    "\n",
    "            ds, fig = plot_preds(scale,raster,preds, tile, group)\n",
    "            ds['lon'] = (roi_[0]+roi_[2])/2\n",
    "            ds['lat'] = (roi_[1]+roi_[3])/2\n",
    "            ds_out = ds_out.append(ds)\n",
    "\n",
    "        return ds_out, fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_figs = '/scratch2/Dropbox/Dropbox/Apps/Overleaf/activelearning_remotesensing/figures/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Palm4748a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "filename = '/home/pf/pfstaff/projects/andresro/barry_palm/data/2A/datasets/palm4748a_base.json'\n",
    "with open(filename, 'rb') as fp:\n",
    "    out_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict['val'][-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_inference = '/scratch/andresro/leon_work/sparse/inference/palm4748a_simpleA9_soft_ens5'\n",
    "scale=20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder_inference = '/home/pf/pfstaff/projects/andresro/sparse/inference_leon/borneo_simpleA9_mc10'\n",
    "ds_out = pd.DataFrame(columns=['GT','Pred','lon','lat'])\n",
    "\n",
    "fig_list = []\n",
    "# tilenames = [x.split('/')[1] for x in out_dict['val']]\n",
    "for x in out_dict['val']:\n",
    "    print(x)\n",
    "#for tile in tilenames:\n",
    "    tile = x.split('/')[1]\n",
    "    group= x.split('/')[2]\n",
    "            \n",
    "    ds_ = plot_counts(folder_inference=folder_inference,\n",
    "                tile=tile,\n",
    "                folder_annotations='/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations',\n",
    "                group=group, scale=scale)\n",
    "    if ds_ is not None:\n",
    "        ds_out = ds_out.append(ds_[0],ignore_index=True)\n",
    "        fig_list.append(ds_[1])\n",
    "    else:\n",
    "        print('error in tile',tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_list[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig_list[5].savefig(save_path_figs+'Density-validation-sumatra-5.pdf', bbox_inches='tight',dpi=300)\n",
    "#fig_list[8].savefig(save_path_figs+'Density-validation-sumatra-8.pdf', bbox_inches='tight',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_ = np.logical_and(ds_out.GT<= 0.1,ds_out.Pred==0)\n",
    "ds = ds_out[~zeros_].copy()\n",
    "\n",
    "# ds['Pred'] = ds.Pred*1.2\n",
    "\n",
    "g = sns.jointplot(x='Pred',y='GT',data=ds, cmap=\"Reds\",\n",
    "#                   kind=\"hex\",\n",
    "                 ) #, clip=(dens_min,dens_max))\n",
    "\n",
    "lims = (0,np.nanmax(ds.GT))\n",
    "g.ax_marg_x.set_xlim(lims)\n",
    "g.ax_marg_y.set_ylim(lims)\n",
    "\n",
    "# lims = [max(x0, y0), min(x1, y1)]\n",
    "g.ax_joint.plot(lims, lims, ':k')    \n",
    "plt.title(f' MAE {np.nanmean(np.abs(ds.Pred -ds.GT))/p2ha(scale):.2f} Trees/ha in {p2ha(scale)}ha Blocks  \\n ' \\\n",
    "          f'total trees GT:{np.nansum(ds.GT):.2f} Pred:{np.nansum(ds.Pred):.2f} ({100*(np.nansum(ds.Pred)-np.nansum(ds.GT))/np.nansum(ds.GT):.2f}%) \\n',x=-0.1,y=0.5, fontsize = 12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to Descals 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_annotations='/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_id(pos_file, grid_file):\n",
    "\n",
    "    pos_vector = ogr.Open(pos_file)\n",
    "    pos_layer = pos_vector.GetLayer()\n",
    "    pos_feature = pos_layer.GetFeature(0)\n",
    "    positiveGeometry = pos_feature.geometry()\n",
    "\n",
    "    grid_vector = ogr.Open(grid_file)\n",
    "    grid_layer = grid_vector.GetLayer()\n",
    "\n",
    "    for i in range(grid_layer.GetFeatureCount()):\n",
    "        feature = grid_layer.GetFeature(i)\n",
    "        vectorGeometry = feature.GetGeometryRef()\n",
    "        if positiveGeometry.Intersects(vectorGeometry):\n",
    "            return feature.GetField('ID')\n",
    "    return -1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_file = '/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations/T48MTD/palm_group2_Bischel/positiv_2.shp'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @no_output\n",
    "def get_rasters(ref_folder):\n",
    "\n",
    "    pos_shp = glob.glob(ref_folder+'/*pos*.shp')\n",
    "    assert len(pos_shp) == 1\n",
    "    pos_file = pos_shp[0]\n",
    "    \n",
    "    \n",
    "    grid_file = '/home/pf/pfstaff/projects/andresro/barry_palm/palmoilmaps/descals2020/grid/grid_withOP.shp'\n",
    "\n",
    "    # Reading Predictions\n",
    "    tile = ref_folder.split('/')[-2]\n",
    "\n",
    "    pred_tif = glob.glob(f'{folder_inference}/{tile}*preds_reg*.tif')[0]\n",
    "\n",
    "    ds = gdal.Open(pred_tif)\n",
    "    ref_proj = ds.GetProjectionRef()\n",
    "\n",
    "    roi_ = gp.get_positive_area_folder(ref_folder)\n",
    "\n",
    "    id_ = get_matching_id(pos_file=pos_file,grid_file=grid_file)\n",
    "\n",
    "    base_path = '/home/pf/pfstaff/projects/andresro/barry_palm/palmoilmaps/descals2020/oil_palm_map'\n",
    "    pred_descals = f'{base_path}/L2_2019b_{id_}.tif'\n",
    "\n",
    "\n",
    "    ds_descals = gdal.Open(pred_descals)\n",
    "\n",
    "    warp_opts = gdal.WarpOptions(\n",
    "        format=\"VRT\",  # format='GTiff',\n",
    "        dstSRS=ref_proj,\n",
    "        resampleAlg=gdalconst.GRA_Bilinear,\n",
    "        # srcNodata=99,\n",
    "        dstNodata='nan')\n",
    "\n",
    "    ds_descals_warped = gdal.Warp('', pred_descals, options=warp_opts)\n",
    "\n",
    "    preds_descals = readHR(data_file=ds_descals_warped,roi_lon_lat=roi_,scale=10, as_float=False, is_assert_blank=False,is_exit=False)\n",
    "    preds_ours = readHR(data_file=ds,roi_lon_lat=roi_,scale=10, as_float=False, is_assert_blank=False,is_exit=False)\n",
    "\n",
    "\n",
    "    lims = gp.to_xy_box(roi_, ds, enlarge=10)\n",
    "\n",
    "    raster_gt = gp.rasterize_points_pos_neg_folder(folder=ref_folder,refDataset=pred_tif,lims=lims,lims_with_labels=lims,sq_kernel=2)\n",
    "    raster_gt[raster_gt == -1] = np.nan\n",
    "\n",
    "    median_s2 = get_median_sentinel2(path='/home/pf/pfstaff/projects/andresro/barry_palm/data/2A/palmcountries_2017/',\n",
    "    ref_tile=tile, roi_lon_lat=roi_, resolution=10)\n",
    "    \n",
    "    return {'gt': raster_gt,\n",
    "            's2': median_s2,\n",
    "            'desc': preds_descals,\n",
    "            'ours':preds_ours,\n",
    "            'roi':roi_}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "all_rasters = {}\n",
    "for ref_folder in tqdm(out_dict['val']):\n",
    "    try:\n",
    "        rasters_dict = get_rasters(folder_annotations+ref_folder)\n",
    "        #fig = plot_rasters(rasters_dict)\n",
    "        all_rasters[ref_folder] = rasters_dict        \n",
    "        #fig_list.append(fig)\n",
    "    except:\n",
    "        print(f'error in {ref_folder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_rasters(rasters_dict, filename = None):\n",
    "        \n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    n_col = 3\n",
    "    gs = gridspec.GridSpec(nrows=2,ncols=n_col,left=0.02, bottom=0.06, right=0.95, top=0.94, wspace=0.1,hspace=0.4, figure=fig)\n",
    "\n",
    "    dens_min = 0.2\n",
    "    dens_max = 2.0\n",
    "\n",
    "    ax = fig.add_subplot(gs[0])\n",
    "    median_s2 = rasters_dict['s2']\n",
    "    raster_gt = rasters_dict['gt']\n",
    "    preds_ours = np.clip(rasters_dict['ours'],0.1,99)\n",
    "    preds_descals = rasters_dict['desc']\n",
    "    \n",
    "    im = ax.imshow(median_s2)\n",
    "\n",
    "    ax = fig.add_subplot(gs[1])\n",
    "        \n",
    "    cmap = mpl.colors.ListedColormap(['white', 'green', 'darkgreen'])\n",
    "    vid = plt.get_cmap('viridis')\n",
    "    vid.set_bad('gray')\n",
    "\n",
    "    #cmap.set_over('0.25')\n",
    "    #cmap.set_under('0.75')\n",
    "    cmap.set_bad(color='gray')\n",
    "\n",
    "    bounds = [0,0.9,2,3]\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "\n",
    "    im = ax.imshow(raster_gt,vmin=dens_min,vmax=dens_max, cmap=vid)\n",
    "    #im = ax.imshow(np.isnan(raster_gt))\n",
    "\n",
    "    #cbar = fig.colorbar(im,ax=ax,orientation='horizontal')\n",
    "    #cbar.ax.set_xlabel(f'Trees/ {p2ha(1):.2f}ha blocks')\n",
    "    ax.set_title(f'Trees GT {np.nansum(raster_gt):.2f}') # ' ({np.nanmax(raster):.2f})')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(f' {raster_gt.shape[0]/100:.2f}km')\n",
    "    ax.set_ylabel(f' {raster_gt.shape[1]/100:.2f}km')\n",
    "\n",
    "    ax = fig.add_subplot(gs[2])\n",
    "\n",
    "    im = ax.imshow(preds_ours,vmin=dens_min,vmax=dens_max)\n",
    "    #cbar = fig.colorbar(im,ax=ax,orientation='horizontal')\n",
    "    #cbar.ax.set_xlabel(f'Trees/ {p2ha(1):.2f}ha blocks')\n",
    "    ax.set_title(f'Trees Pred {np.nansum(preds_ours):.2f}') #' ({np.nanmax(preds):.2f})')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(f' {preds_ours.shape[0]/100:.2f}km')#  \\n\\n'+txt)\n",
    "    ax.set_ylabel(f' {preds_ours.shape[1]/100:.2f}km')\n",
    "\n",
    "\n",
    "    ax = fig.add_subplot(gs[3])\n",
    "\n",
    "    threshold_area = 0.5\n",
    "    \n",
    "    raster_gt_sem = (raster_gt > threshold_area)*1.\n",
    "    raster_gt_sem[np.isnan(raster_gt)] = np.nan\n",
    "\n",
    "    im = ax.imshow(raster_gt_sem,cmap =cmap,norm=norm) # ,vmin=dens_min,vmax=dens_max)\n",
    "    #cbar = fig.colorbar(im,ax=ax,orientation='horizontal')\n",
    "    #cbar.ax.set_xlabel(f'Trees/ {p2ha(1):.2f}ha blocks')\n",
    "    ax.set_title(f'Area GT {np.nansum(raster_gt > threshold_area):.0f}') #' ({np.nanmax(preds):.2f})')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(f' {preds_ours.shape[0]/100:.2f}km')#  \\n\\n'+txt)\n",
    "    ax.set_ylabel(f' {preds_ours.shape[1]/100:.2f}km')\n",
    "\n",
    "    ax = fig.add_subplot(gs[4])\n",
    "\n",
    "    im = ax.imshow(preds_ours > threshold_area, cmap =cmap, norm=norm) # ,vmin=dens_min,vmax=dens_max)\n",
    "    #cbar = fig.colorbar(im,ax=ax,orientation='horizontal')\n",
    "    #cbar.ax.set_xlabel(f'Trees/ {p2ha(1):.2f}ha blocks')\n",
    "    ax.set_title(f'Area Pred {np.sum(preds_ours[~np.isnan(raster_gt)] >threshold_area):.0f}') #' ({np.nanmax(preds):.2f})')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(f' {preds_ours.shape[0]/100:.2f}km')#  \\n\\n'+txt)\n",
    "    ax.set_ylabel(f' {preds_ours.shape[1]/100:.2f}km')\n",
    "\n",
    "    ax = fig.add_subplot(gs[5])\n",
    "\n",
    "    im = ax.imshow(3 - preds_descals ,cmap =cmap,norm=norm) # cmap=cmap) # ,vmin=dens_min,vmax=dens_max)\n",
    "    #cbar = fig.colorbar(im,ax=ax,orientation='horizontal')\n",
    "    #cbar.ax.set_xlabel(f'Trees/ {p2ha(1):.2f}ha blocks')\n",
    "    print(preds_descals.shape, raster_gt.shape, preds_ours.shape)\n",
    "    try:\n",
    "    \n",
    "        ax.set_title(f'Area Descals {np.sum(preds_descals[~np.isnan(raster_gt)] == 2):.0f}') #' ({np.nanmax(preds):.2f})')\n",
    "    except IndexError:\n",
    "        print(preds_descals.shape,preds_ours.shape, raster_gt.shape,)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(f' {preds_ours.shape[0]/100:.2f}km')#  \\n\\n'+txt)\n",
    "    ax.set_ylabel(f' {preds_ours.shape[1]/100:.2f}km')\n",
    "    \n",
    "    if filename is not None:\n",
    "        fig.savefig(filename, bbox_inches='tight',dpi=300)\n",
    "        print(filename,'saved!')\n",
    "    #return fig\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rasters.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt = all_rasters['/T48NUG/palm_group2']['gt']\n",
    "\n",
    "# desc = all_rasters['/T48NUG/palm_group2']['desc']\n",
    "# gt_sem = 1.*(gt > 0.5)\n",
    "# gt_sem[np.isnan(gt)] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "# cmap = mpl.colors.ListedColormap(['white', 'darkgreen','red'])\n",
    "\n",
    "# #cmap.set_over('0.25')\n",
    "# #cmap.set_under('0.75')\n",
    "# cmap.set_bad(color='gray')\n",
    "\n",
    "# bounds = [0,0.9,2,3]\n",
    "# norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# plt.imshow(gt_sem,cmap=cmap, norm=norm)\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "# plt.imshow(3- desc,cmap=cmap,norm=norm)\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for key, val in all_rasters.items():\n",
    "    plot_rasters(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rasters.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rasters(all_rasters['/T48NUG/palm_group2'], filename=save_path_figs+'/comparsion_descals.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation areas from Descals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_val = '/home/pf/pfstaff/projects/andresro/barry_palm/palmoilmaps/descals2020/Validation_points_GlobalOilPalmLayer_2019/Validation_points_GlobalOilPalmLayer_2019.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel_2tiles = '/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/sentinel2_tiles_world/sentinel2_tiles_world.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tif = glob.glob(folder_inference+'/T*.tif')\n",
    "\n",
    "list_tif = [x.split('/')[-1] for x in list_tif]\n",
    "list_tif = {x.split('_')[0][1:] for x in list_tif}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_s2 = ogr.Open(sentinel_2tiles)\n",
    "layer_s2 = vector_s2.GetLayer()\n",
    "nfeat_s2 = layer_s2.GetFeatureCount()\n",
    "\n",
    "feat_list = []\n",
    "for i in range(nfeat_s2):\n",
    "    feature_s2 = layer_s2.GetFeature(i)\n",
    "    if feature_s2.GetField('NAME') in list_tif:\n",
    "        feat_list.append(i)\n",
    "\n",
    "\n",
    "def get_s2_name(ref_geom):\n",
    "    for i in feat_list:\n",
    "        feature_s2 = layer_s2.GetFeature(i)\n",
    "        geom_s2 = feature_s2.GetGeometryRef()\n",
    "        if ref_geom.Intersects(geom_s2):\n",
    "            return feature_s2.GetField('NAME')\n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = ogr.Open(shp_val)\n",
    "layer = vector.GetLayer()\n",
    "# feature = layer.GetFeature(0)\n",
    "# positiveGeometry = pos_feature.geometry()\n",
    "\n",
    "# grid_vector = ogr.Open(grid_file)\n",
    "# grid_layer = grid_vector.GetLayer()\n",
    "ids = []\n",
    "gt = []\n",
    "pred_desc = []\n",
    "s2_names = []\n",
    "for i in range(layer.GetFeatureCount()):\n",
    "    feature = layer.GetFeature(i)\n",
    "    vectorGeometry = feature.GetGeometryRef()\n",
    "    s2_name = get_s2_name(vectorGeometry)\n",
    "    if s2_name is not None:\n",
    "        ids.append(i)\n",
    "        gt.append(feature.GetField('Class'))\n",
    "        pred_desc.append(feature.GetField('predClass'))\n",
    "        s2_names.append(s2_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true=np.clip(gt,0,1),y_pred=np.clip(pred_desc,0,1)).ravel()\n",
    "\n",
    "output_ = {}\n",
    "output_['acc'] = (tp + tn) / (tp +tn + fn + fp)\n",
    "output_['prec'] = (tp) / (tp + fp)\n",
    "output_['rec'] = (tp) / (tp + fn)\n",
    "output_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ours = []\n",
    "lonlats = []\n",
    "for id_, s2_name in zip(ids,s2_names):\n",
    "    ds = glob.glob(f'{folder_inference}/T{s2_name}*.tif')\n",
    "    if len(ds) > 0:\n",
    "        ds = gdal.Open(ds[0])\n",
    "        feature = layer.GetFeature(id_)\n",
    "        vectorGeometry = feature.GetGeometryRef()\n",
    "        lon, lat, _ = vectorGeometry.GetPoint(0)\n",
    "        x, y = gp.to_xy(lon,lat,ds =ds)\n",
    "        lonlats.append((lon,lat))\n",
    "        array = ds.ReadAsArray(xoff=x,yoff=y,xsize=1,ysize=1)\n",
    "        pred_ours.append(array)\n",
    "    else:\n",
    "        pred_ours.append([np.nan])\n",
    "        lonlats.append((np.nan,np.nan))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ours = np.array(pred_ours).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sem = (pred_ours > 0.4)*1.\n",
    "tn, fp, fn, tp = confusion_matrix(y_true=np.clip(gt,0,1),y_pred=pred_sem).ravel()\n",
    "\n",
    "output_ = {}\n",
    "output_['acc'] = (tp + tn) / (tp +tn + fn + fp)\n",
    "output_['prec'] = (tp) / (tp + fp)\n",
    "output_['rec'] = (tp) / (tp + fn)\n",
    "output_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PALM 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "filename = '/home/pf/pfstaff/projects/andresro/barry_palm/data/2A/datasets/palm4_base.json'\n",
    "with open(filename, 'rb') as fp:\n",
    "    out_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict['val'][-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_inference = '/scratch/andresro/leon_work/sparse/inference/palm4_simpleA9_soft_ens5'\n",
    "scale=20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "all_rasters = {}\n",
    "for ref_folder in tqdm(out_dict['val']):\n",
    "    try:\n",
    "        tile = ref_folder.split('/')[1]\n",
    "        group= ref_folder.split('/')[2]\n",
    "        rasters_dict = get_rasters(folder_inference=folder_inference,\n",
    "                tile=tile,\n",
    "                folder_annotations='/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations',\n",
    "                group=group, scale=scale)\n",
    "        #fig = plot_rasters(rasters_dict)\n",
    "        all_rasters[ref_folder] = rasters_dict        \n",
    "        #fig_list.append(fig)\n",
    "    except:\n",
    "        print(f'error in {ref_folder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 10\n",
    "dens_min = 0.3\n",
    "ds_out = pd.DataFrame(columns=['GT','Pred','lon','lat'])\n",
    "\n",
    "\n",
    "for key, val in all_rasters.items():\n",
    "    raster = val['gt']\n",
    "    preds = val['preds']\n",
    "    roi_ = val['roi_']\n",
    "    \n",
    "    mask_out = np.isnan(raster) | np.isnan(preds) | (preds == 99)\n",
    "    preds1 = preds.copy()\n",
    "    preds1[preds1 < dens_min] = 0.0\n",
    "    preds1[mask_out] = np.nan\n",
    "    raster1 = raster.copy()\n",
    "    raster1[mask_out] = np.nan\n",
    "\n",
    "#     print(p2ha(scale))\n",
    "    r1 = gp.block_reduce(raster1,(scale,scale),np.nansum)\n",
    "    p1 = gp.block_reduce(preds1,(scale,scale),np.nansum)\n",
    "    \n",
    "    ds_ = pd.DataFrame({'GT':r1.ravel(),'Pred':p1.ravel(),\n",
    "                       'lon':(roi_[0]+roi_[2])/2,\n",
    "                       'lat':(roi_[1]+roi_[3])/2})\n",
    "    \n",
    "    #             ds['lon'] = (roi_[0]+roi_[2])/2\n",
    "#             ds['lat'] = (roi_[1]+roi_[3])/2\n",
    "    ds_out = ds_out.append(ds_,ignore_index=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_trees = 1\n",
    "zeros_ = np.logical_or(ds_out.GT < min_trees,ds_out.Pred < min_trees)\n",
    "ds = ds_out.copy() # [~zeros_].copy()\n",
    "ds = ds[~zeros_]\n",
    "\n",
    "ds['Pred'] = ds.Pred*1.2\n",
    "\n",
    "g = sns.jointplot(x='Pred',y='GT',data=ds,\n",
    "#                   cmap=\"Reds\",\n",
    "                  kind='reg',scatter=False,\n",
    "#                    kind=\"hex\",\n",
    "                 ) #, clip=(dens_min,dens_max))\n",
    "\n",
    "g.ax_joint.scatter(x=ds.Pred,y=ds.GT, color='lightgray')\n",
    "lims = (0,np.nanmax(ds.GT))\n",
    "g.ax_marg_x.set_xlim(lims)\n",
    "g.ax_marg_y.set_ylim(lims)\n",
    "\n",
    "# lims = [max(x0, y0), min(x1, y1)]\n",
    "g.ax_joint.plot(lims, lims, ':k')    \n",
    "plt.title(f' MAE {np.nanmean(np.abs(ds.Pred -ds.GT))/p2ha(scale):.2f} Trees/ha in {p2ha(scale)}ha Blocks  \\n ' \\\n",
    "#           f'total trees GT:{np.nansum(ds.GT):.2f} Pred:{np.nansum(ds.Pred):.2f} ({100*(np.nansum(ds.Pred)-np.nansum(ds.GT))/np.nansum(ds.GT):.2f}%) \\n' \\\n",
    "          ' \\n\\n\\n',\n",
    "           x=0.7,\n",
    "           fontsize = 14)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#folder_inference = '/home/pf/pfstaff/projects/andresro/sparse/inference_leon/borneo_simpleA9_mc10'\n",
    "ds_out = pd.DataFrame(columns=['GT','Pred','lon','lat'])\n",
    "\n",
    "fig_list = []\n",
    "# tilenames = [x.split('/')[1] for x in out_dict['val']]\n",
    "for x in out_dict['val']:\n",
    "    print(x)\n",
    "#for tile in tilenames:\n",
    "    tile = x.split('/')[1]\n",
    "    group= x.split('/')[2]\n",
    "            \n",
    "    ds_ = plot_counts(folder_inference=folder_inference,\n",
    "                tile=tile,\n",
    "                folder_annotations='/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations',\n",
    "                group=group, scale=scale, clip_min=0.2)\n",
    "    if ds_ is not None:\n",
    "        ds_out = ds_out.append(ds_[0],ignore_index=True)\n",
    "        fig_list.append(ds_[1])\n",
    "    else:\n",
    "        print('error in tile',tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#folder_inference = '/home/pf/pfstaff/projects/andresro/sparse/inference_leon/borneo_simpleA9_mc10'\n",
    "ds_out = pd.DataFrame(columns=['GT','Pred','lon','lat'])\n",
    "\n",
    "fig_list = []\n",
    "# tilenames = [x.split('/')[1] for x in out_dict['val']]\n",
    "for x in out_dict['val']:\n",
    "    print(x)\n",
    "#for tile in tilenames:\n",
    "    tile = x.split('/')[1]\n",
    "    group= x.split('/')[2]\n",
    "            \n",
    "    ds_ = plot_counts(folder_inference=folder_inference,\n",
    "                tile=tile,\n",
    "                folder_annotations='/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations',\n",
    "                group=group, scale=scale, clip_min=0.4)\n",
    "    if ds_ is not None:\n",
    "        ds_out = ds_out.append(ds_[0],ignore_index=True)\n",
    "        fig_list.append(ds_[1])\n",
    "    else:\n",
    "        print('error in tile',tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig_list[5].savefig(save_path_figs+'Density-validation-sumatra-5.pdf', bbox_inches='tight',dpi=300)\n",
    "#fig_list[8].savefig(save_path_figs+'Density-validation-sumatra-8.pdf', bbox_inches='tight',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ = ds_out.groupby(['lon','lat']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gdf = geopandas.GeoDataFrame(\n",
    "    geometry=geopandas.points_from_xy(d_['lon'],  d_['lat']))\n",
    "\n",
    "error_ = np.abs(d_.Pred -d_.GT)\n",
    "\n",
    "world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "countries = geopandas.read_file(\"/scratch/andresro/leon_work/barry_palm/data/labels/countries/3countries.shp\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "world.plot(ax=ax,\n",
    "    color='lightgray', edgecolor='white')\n",
    "\n",
    "#countries.plot(ax=ax,\n",
    "#    color='lightgray', edgecolor='white')\n",
    "\n",
    "\n",
    "# sm = gdf.plot(ax=ax, marker='.',\n",
    "# # color='blue',\n",
    "#          c=error_,\n",
    "#                 label='Val'\n",
    "#          )\n",
    "\n",
    "\n",
    "sc = ax.scatter(d_['lon'], d_['lat'],\n",
    "            c=np.abs(d_.Pred -d_.GT),\n",
    "            # c=weight_sorted[:top_k],\n",
    "            cmap='magma',\n",
    "           marker='.')\n",
    "\n",
    "plt.colorbar(sc,ax=ax,orientation=\"horizontal\")\n",
    "\n",
    "\n",
    "minx, miny, maxx, maxy = gdf.total_bounds\n",
    "margin_x = 2\n",
    "margin_y = 2\n",
    "\n",
    "\n",
    "ax.set_xlim(minx-margin_x, maxx+margin_x)\n",
    "ax.set_ylim(miny-margin_y, maxy+margin_y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gl = ax.gridlines(\n",
    "   crs=ccrs.PlateCarree(),\n",
    "    draw_labels=True) #x_inline=False, y_inline=False)\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "gl.xlabel_style = {'rotation':'vertical'}\n",
    "\n",
    "\n",
    "# ax.legend(bbox_to_anchor=(1, 0.75), loc='upper left', ncol=1,\n",
    "#          title=\"Sample Type\")\n",
    "#ax.legend() # loc='lower left')\n",
    "\n",
    "# plt.title('Active Learning Selected Samples\\n\\n')\n",
    "# plt.savefig(save_path_figs + 'active_learning_samples_10opt.', bbox_inches='tight', dpi= 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ds_out['lon'], ds_out['lat'],\n",
    "            c=np.abs(ds_out.Pred -ds_out.GT),\n",
    "            # c=weight_sorted[:top_k],\n",
    "            cmap='magma_r', marker='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds.GT == 0.1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zeros_ = np.logical_and(ds_out.GT== 0.1,ds_out.Pred==0)\n",
    "ds = ds_out # [~zeros_].copy()\n",
    "\n",
    "ds['Pred'] = ds.Pred*1.2\n",
    "\n",
    "g = sns.jointplot(x='Pred',y='GT',data=ds, cmap=\"Reds\",\n",
    "#                   kind=\"hex\",\n",
    "                 ) #, clip=(dens_min,dens_max))\n",
    "\n",
    "lims = (0,np.nanmax(ds.GT))\n",
    "g.ax_marg_x.set_xlim(lims)\n",
    "g.ax_marg_y.set_ylim(lims)\n",
    "\n",
    "# lims = [max(x0, y0), min(x1, y1)]\n",
    "g.ax_joint.plot(lims, lims, ':k')    \n",
    "plt.title(f' MAE {np.nanmean(np.abs(ds.Pred -ds.GT))/p2ha(scale):.2f} Trees/ha in {p2ha(scale)}ha Blocks  \\n ' \\\n",
    "          f'total trees GT:{np.nansum(ds.GT):.2f} Pred:{np.nansum(ds.Pred):.2f} ({100*(np.nansum(ds.Pred)-np.nansum(ds.GT))/np.nansum(ds.GT):.2f}%) \\n',x=-0.1,y=0.5, fontsize = 12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to Descals 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_annotations='/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_id(pos_file, grid_file):\n",
    "\n",
    "    pos_vector = ogr.Open(pos_file)\n",
    "    pos_layer = pos_vector.GetLayer()\n",
    "    pos_feature = pos_layer.GetFeature(0)\n",
    "    positiveGeometry = pos_feature.geometry()\n",
    "\n",
    "    grid_vector = ogr.Open(grid_file)\n",
    "    grid_layer = grid_vector.GetLayer()\n",
    "\n",
    "    for i in range(grid_layer.GetFeatureCount()):\n",
    "        feature = grid_layer.GetFeature(i)\n",
    "        vectorGeometry = feature.GetGeometryRef()\n",
    "        if positiveGeometry.Intersects(vectorGeometry):\n",
    "            return feature.GetField('ID')\n",
    "    return -1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_file = '/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations/T48MTD/palm_group2_Bischel/positiv_2.shp'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @no_output\n",
    "def get_rasters(ref_folder):\n",
    "\n",
    "    pos_shp = glob.glob(ref_folder+'/*pos*.shp')\n",
    "    assert len(pos_shp) == 1\n",
    "    pos_file = pos_shp[0]\n",
    "    \n",
    "    \n",
    "    grid_file = '/home/pf/pfstaff/projects/andresro/barry_palm/palmoilmaps/descals2020/grid/grid_withOP.shp'\n",
    "\n",
    "    # Reading Predictions\n",
    "    tile = ref_folder.split('/')[-2]\n",
    "\n",
    "    pred_tif = glob.glob(f'{folder_inference}/{tile}*preds_reg*.tif')[0]\n",
    "\n",
    "    ds = gdal.Open(pred_tif)\n",
    "    ref_proj = ds.GetProjectionRef()\n",
    "\n",
    "    roi_ = gp.get_positive_area_folder(ref_folder)\n",
    "\n",
    "    id_ = get_matching_id(pos_file=pos_file,grid_file=grid_file)\n",
    "\n",
    "    base_path = '/home/pf/pfstaff/projects/andresro/barry_palm/palmoilmaps/descals2020/oil_palm_map'\n",
    "    pred_descals = f'{base_path}/L2_2019b_{id_}.tif'\n",
    "\n",
    "\n",
    "    ds_descals = gdal.Open(pred_descals)\n",
    "\n",
    "    warp_opts = gdal.WarpOptions(\n",
    "        format=\"VRT\",  # format='GTiff',\n",
    "        dstSRS=ref_proj,\n",
    "        resampleAlg=gdalconst.GRA_Bilinear,\n",
    "        # srcNodata=99,\n",
    "        dstNodata='nan')\n",
    "\n",
    "    ds_descals_warped = gdal.Warp('', pred_descals, options=warp_opts)\n",
    "\n",
    "    preds_descals = readHR(data_file=ds_descals_warped,roi_lon_lat=roi_,scale=10, as_float=False, is_assert_blank=False,is_exit=False)\n",
    "    preds_ours = readHR(data_file=ds,roi_lon_lat=roi_,scale=10, as_float=False, is_assert_blank=False,is_exit=False)\n",
    "\n",
    "\n",
    "    lims = gp.to_xy_box(roi_, ds, enlarge=10)\n",
    "\n",
    "    raster_gt = gp.rasterize_points_pos_neg_folder(folder=ref_folder,refDataset=pred_tif,lims=lims,lims_with_labels=lims,sq_kernel=2)\n",
    "    raster_gt[raster_gt == -1] = np.nan\n",
    "\n",
    "    median_s2 = get_median_sentinel2(path='/home/pf/pfstaff/projects/andresro/barry_palm/data/2A/palmcountries_2017/',\n",
    "    ref_tile=tile, roi_lon_lat=roi_, resolution=10)\n",
    "    \n",
    "    return {'gt': raster_gt,\n",
    "            's2': median_s2,\n",
    "            'desc': preds_descals,\n",
    "            'ours':preds_ours}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "all_rasters = {}\n",
    "for ref_folder in tqdm(out_dict['val']):\n",
    "    try:\n",
    "        rasters_dict = get_rasters(folder_annotations+ref_folder)\n",
    "        #fig = plot_rasters(rasters_dict)\n",
    "        all_rasters[ref_folder] = rasters_dict        \n",
    "        #fig_list.append(fig)\n",
    "    except:\n",
    "        print(f'error in {ref_folder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "def plot_rasters(rasters_dict, filename = None):\n",
    "        \n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    n_col = 3\n",
    "    gs = gridspec.GridSpec(nrows=2,ncols=n_col,left=0.02, bottom=0.06, right=0.95, top=0.94, wspace=0.1,hspace=0.4, figure=fig)\n",
    "\n",
    "    dens_min = 0.2\n",
    "    dens_max = 2.0\n",
    "\n",
    "    ax = fig.add_subplot(gs[0])\n",
    "    median_s2 = rasters_dict['s2']\n",
    "    raster_gt = rasters_dict['gt']\n",
    "    preds_ours = np.clip(rasters_dict['ours'],0.1,99)\n",
    "    preds_descals = rasters_dict['desc']\n",
    "    \n",
    "    im = ax.imshow(median_s2)\n",
    "\n",
    "    ax = fig.add_subplot(gs[1])\n",
    "        \n",
    "    cmap = mpl.colors.ListedColormap(['white', 'green', 'darkgreen'])\n",
    "    vid = plt.get_cmap('viridis')\n",
    "    vid.set_bad('gray')\n",
    "\n",
    "    #cmap.set_over('0.25')\n",
    "    #cmap.set_under('0.75')\n",
    "    cmap.set_bad(color='gray')\n",
    "\n",
    "    bounds = [0,0.9,2,3]\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "\n",
    "    im = ax.imshow(raster_gt,vmin=dens_min,vmax=dens_max, cmap=vid)\n",
    "    #im = ax.imshow(np.isnan(raster_gt))\n",
    "\n",
    "    #cbar = fig.colorbar(im,ax=ax,orientation='horizontal')\n",
    "    #cbar.ax.set_xlabel(f'Trees/ {p2ha(1):.2f}ha blocks')\n",
    "    ax.set_title(f'Trees GT {np.nansum(raster_gt):.2f}') # ' ({np.nanmax(raster):.2f})')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(f' {raster_gt.shape[0]/100:.2f}km')\n",
    "    ax.set_ylabel(f' {raster_gt.shape[1]/100:.2f}km')\n",
    "\n",
    "    ax = fig.add_subplot(gs[2])\n",
    "\n",
    "    im = ax.imshow(preds_ours,vmin=dens_min,vmax=dens_max)\n",
    "    #cbar = fig.colorbar(im,ax=ax,orientation='horizontal')\n",
    "    #cbar.ax.set_xlabel(f'Trees/ {p2ha(1):.2f}ha blocks')\n",
    "    ax.set_title(f'Trees Pred {np.nansum(preds_ours):.2f}') #' ({np.nanmax(preds):.2f})')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(f' {preds_ours.shape[0]/100:.2f}km')#  \\n\\n'+txt)\n",
    "    ax.set_ylabel(f' {preds_ours.shape[1]/100:.2f}km')\n",
    "\n",
    "\n",
    "    ax = fig.add_subplot(gs[3])\n",
    "\n",
    "    threshold_area = 0.5\n",
    "    \n",
    "    raster_gt_sem = (raster_gt > threshold_area)*1.\n",
    "    raster_gt_sem[np.isnan(raster_gt)] = np.nan\n",
    "\n",
    "    im = ax.imshow(raster_gt_sem,cmap =cmap,norm=norm) # ,vmin=dens_min,vmax=dens_max)\n",
    "    #cbar = fig.colorbar(im,ax=ax,orientation='horizontal')\n",
    "    #cbar.ax.set_xlabel(f'Trees/ {p2ha(1):.2f}ha blocks')\n",
    "    ax.set_title(f'Area GT {np.nansum(raster_gt > threshold_area):.0f}') #' ({np.nanmax(preds):.2f})')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(f' {preds_ours.shape[0]/100:.2f}km')#  \\n\\n'+txt)\n",
    "    ax.set_ylabel(f' {preds_ours.shape[1]/100:.2f}km')\n",
    "\n",
    "    ax = fig.add_subplot(gs[4])\n",
    "\n",
    "    im = ax.imshow(preds_ours > threshold_area, cmap =cmap, norm=norm) # ,vmin=dens_min,vmax=dens_max)\n",
    "    #cbar = fig.colorbar(im,ax=ax,orientation='horizontal')\n",
    "    #cbar.ax.set_xlabel(f'Trees/ {p2ha(1):.2f}ha blocks')\n",
    "    ax.set_title(f'Area Pred {np.sum(preds_ours[~np.isnan(raster_gt)] >threshold_area):.0f}') #' ({np.nanmax(preds):.2f})')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(f' {preds_ours.shape[0]/100:.2f}km')#  \\n\\n'+txt)\n",
    "    ax.set_ylabel(f' {preds_ours.shape[1]/100:.2f}km')\n",
    "\n",
    "    ax = fig.add_subplot(gs[5])\n",
    "\n",
    "    im = ax.imshow(3 - preds_descals ,cmap =cmap,norm=norm) # cmap=cmap) # ,vmin=dens_min,vmax=dens_max)\n",
    "    #cbar = fig.colorbar(im,ax=ax,orientation='horizontal')\n",
    "    #cbar.ax.set_xlabel(f'Trees/ {p2ha(1):.2f}ha blocks')\n",
    "    print(preds_descals.shape, raster_gt.shape, preds_ours.shape)\n",
    "    try:\n",
    "    \n",
    "        ax.set_title(f'Area Descals {np.sum(preds_descals[~np.isnan(raster_gt)] == 2):.0f}') #' ({np.nanmax(preds):.2f})')\n",
    "    except IndexError:\n",
    "        print(preds_descals.shape,preds_ours.shape, raster_gt.shape,)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(f' {preds_ours.shape[0]/100:.2f}km')#  \\n\\n'+txt)\n",
    "    ax.set_ylabel(f' {preds_ours.shape[1]/100:.2f}km')\n",
    "    \n",
    "    if filename is not None:\n",
    "        fig.savefig(filename, bbox_inches='tight',dpi=300)\n",
    "        print(filename,'saved!')\n",
    "    #return fig\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict['val'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_rasters.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt = all_rasters['/T48NUG/palm_group2']['gt']\n",
    "\n",
    "# desc = all_rasters['/T48NUG/palm_group2']['desc']\n",
    "# gt_sem = 1.*(gt > 0.5)\n",
    "# gt_sem[np.isnan(gt)] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "# cmap = mpl.colors.ListedColormap(['white', 'darkgreen','red'])\n",
    "\n",
    "# #cmap.set_over('0.25')\n",
    "# #cmap.set_under('0.75')\n",
    "# cmap.set_bad(color='gray')\n",
    "\n",
    "# bounds = [0,0.9,2,3]\n",
    "# norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# plt.imshow(gt_sem,cmap=cmap, norm=norm)\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "# plt.imshow(3- desc,cmap=cmap,norm=norm)\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for key, val in all_rasters.items():\n",
    "    plot_rasters(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rasters.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rasters(all_rasters['/T48NUG/palm_group2'], filename=save_path_figs+'/comparsion_descals.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rasters(all_rasters['/T48NUG/palm_group2'], filename=save_path_figs+'/comparsion_descals.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation areas from Descals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_val = '/home/pf/pfstaff/projects/andresro/barry_palm/palmoilmaps/descals2020/Validation_points_GlobalOilPalmLayer_2019/Validation_points_GlobalOilPalmLayer_2019.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel_2tiles = '/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/sentinel2_tiles_world/sentinel2_tiles_world.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tif = glob.glob(folder_inference+'/T*.tif')\n",
    "\n",
    "list_tif = [x.split('/')[-1] for x in list_tif]\n",
    "list_tif = {x.split('_')[0][1:] for x in list_tif}\n",
    "len(list_tif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_s2 = ogr.Open(sentinel_2tiles)\n",
    "layer_s2 = vector_s2.GetLayer()\n",
    "nfeat_s2 = layer_s2.GetFeatureCount()\n",
    "\n",
    "feat_list = []\n",
    "for i in range(nfeat_s2):\n",
    "    feature_s2 = layer_s2.GetFeature(i)\n",
    "    if feature_s2.GetField('NAME') in list_tif:\n",
    "        feat_list.append(i)\n",
    "\n",
    "\n",
    "def get_s2_name(ref_geom):\n",
    "    for i in feat_list:\n",
    "        feature_s2 = layer_s2.GetFeature(i)\n",
    "        geom_s2 = feature_s2.GetGeometryRef()\n",
    "        if ref_geom.Intersects(geom_s2):\n",
    "            return feature_s2.GetField('NAME')\n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = ogr.Open(shp_val)\n",
    "layer = vector.GetLayer()\n",
    "\n",
    "ids = []\n",
    "gt = []\n",
    "pred_desc = []\n",
    "s2_names = []\n",
    "for i in range(layer.GetFeatureCount()):\n",
    "    feature = layer.GetFeature(i)\n",
    "    vectorGeometry = feature.GetGeometryRef()\n",
    "    s2_name = get_s2_name(vectorGeometry)\n",
    "    if s2_name is not None:\n",
    "        ids.append(i)\n",
    "        gt.append(feature.GetField('Class'))\n",
    "        pred_desc.append(feature.GetField('predClass'))\n",
    "        s2_names.append(s2_name)\n",
    "print('matched points',len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true=np.clip(gt,0,1),y_pred=np.clip(pred_desc,0,1)).ravel()\n",
    "\n",
    "output_ = {}\n",
    "output_['acc'] = (tp + tn) / (tp +tn + fn + fp)\n",
    "output_['prec'] = (tp) / (tp + fp)\n",
    "output_['rec'] = (tp) / (tp + fn)\n",
    "output_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Producer's accuracy = Recall ' the number of reference sites classified accurately divided by the total number of reference sites for that class. '\n",
    "\n",
    "User's Accuracy = Precision The User's Accuracy is calculating by taking the total number of correct classifications for a particular class and dividing it by the row total.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ours = []\n",
    "lonlats = []\n",
    "window_size = 3 # each side\n",
    "patch_size = 2*window_size+1\n",
    "\n",
    "for id_, s2_name in tqdm(zip(ids,s2_names)):\n",
    "    ds = glob.glob(f'{folder_inference}/T{s2_name}*.tif')\n",
    "    if len(ds) > 0:\n",
    "        ds = gdal.Open(ds[0])\n",
    "        feature = layer.GetFeature(id_)\n",
    "        vectorGeometry = feature.GetGeometryRef()\n",
    "        lon, lat, _ = vectorGeometry.GetPoint(0)\n",
    "        x, y = gp.to_xy(lon,lat,ds =ds)\n",
    "        x = np.clip(x-window_size, 0,ds.RasterXSize-patch_size)\n",
    "        y = np.clip(y-window_size, 0,ds.RasterYSize-patch_size)\n",
    "        \n",
    "        lonlats.append((lon,lat))\n",
    "#         array = ds.ReadAsArray(xoff=x,yoff=y,xsize=1,ysize=1)\n",
    "        array = ds.ReadAsArray(xoff=int(x),yoff=int(y),xsize=patch_size,ysize=patch_size).mean()\n",
    "        pred_ours.append(array)\n",
    "    else:\n",
    "        pred_ours.append([np.nan])\n",
    "        lonlats.append((np.nan,np.nan))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ours = np.array(pred_ours).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sem = (pred_ours > 0.48)*1.\n",
    "tn, fp, fn, tp = confusion_matrix(y_true=np.clip(gt,0,1),y_pred=pred_sem).ravel()\n",
    "\n",
    "output_ = {}\n",
    "output_['acc'] = (tp + tn) / (tp +tn + fn + fp)\n",
    "output_['prec'] = (tp) / (tp + fp)\n",
    "output_['rec'] = (tp) / (tp + fn)\n",
    "output_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_shp(points):\n",
    "    if points.endswith('.kml'):\n",
    "        new_points=points.replace('.kml','.shp')\n",
    "        srcDS = gdal.OpenEx(points)\n",
    "        ds = gdal.VectorTranslate(new_points, srcDS, format='ESRI Shapefile')\n",
    "        ds = None\n",
    "        points = new_points\n",
    "    return points \n",
    "\n",
    "\n",
    "def drop_all_butName(points):\n",
    "    dataSource = ogr.Open(points, 1) \n",
    "\n",
    "    layer = dataSource.GetLayer()\n",
    "\n",
    "    lyrdf = layer.GetLayerDefn()\n",
    "\n",
    "    id_Name = lyrdf.GetFieldIndex('Name')\n",
    "    attr_N = lyrdf.GetFieldCount()\n",
    "    print(attr_N, id_Name)\n",
    "    for i in range(attr_N):\n",
    "        if not i == id_Name:\n",
    "            layer.DeleteField(i)   \n",
    "    attr_N = lyrdf.GetFieldCount()\n",
    "    print(attr_N)\n",
    "    dataSource = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_raster = '/scratch/andresro/leon_work/sparse/inference/palmcoco_kalimA_simpleA5/R132_T49MCV_preds_reg.tif'\n",
    "for i in range(3):\n",
    "    points = f'/home/pf/pfstud/andresro/tree_annotationsAug2019/annotations/Jan/palm/49MCV/Palm_Jan_{i+1}.kml'\n",
    "    points = convert_to_shp(points)\n",
    "    print(points)\n",
    "    loop_zonal_stats_update(input_zone_polygon=points,input_value_raster=ref_raster,fieldname='pred1',fn=np.ma.sum, is_update=False, is_pos_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_raster = '/scratch/andresro/leon_work/sparse/inference/palmcoco_kalimA_simpleA5/R018_T47NQA_preds_reg.tif'\n",
    "points = '/home/pf/pfstud/andresro/tree_annotationsAug2019/annotations/Andres/palm/points_manual_2019.kml'\n",
    "points = convert_to_shp(points)\n",
    "print(points)\n",
    "if os.path.isdir(points):\n",
    "    pointsList = glob.glob(points+\"/*.shp\")\n",
    "    print(f'processing {len(pointsList)} layers')\n",
    "else:\n",
    "    pointsList = [points]\n",
    "\n",
    "for points in pointsList:\n",
    "    \n",
    "    out_val = loop_zonal_stats_update(input_zone_polygon=points,input_value_raster=ref_raster,fieldname='pred1',fn=np.ma.sum, is_update=False)\n",
    "    print(f\"TOTAL {out_val:.2f}\", os.path.basename(points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate state-wide predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 2\n",
    "input_zone_pol = '/scratch2/Dropbox/Dropbox/0_phd/tree_annotationsAug2019/countries/malaysia/MYS_adm1.shp'\n",
    "ref_raster = f'/scratch/andresro/leon_work/sparse/inference/palmsarawak_simpleA20_allsarawak/0_untiled_down{scale}.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = gp.rasterize_polygons(InputVector=input_zone_pol,refDataset=ref_raster,attribute='ID_1')\n",
    "\n",
    "raster = readHR(roi_lon_lat = None,data_file=ref_raster,scale=1,as_float=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(img==11)\n",
    "raster[img!=11] = np.nan\n",
    "raster *=(scale**2) # computing sum instead of average in down op \n",
    "raster*=1.4 # bias correction\n",
    "\n",
    "plt.imshow(raster)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2ha(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmin(raster),np.nanmax(raster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Ha\n",
    "ref_ = raster  > 30*p2ha(scale)\n",
    "plt.imshow(ref_)\n",
    "area = np.nansum(ref_)*p2ha(scale)\n",
    "trees = np.nansum(raster[ref_])\n",
    "f' Planted {area/1e6:.3f}mha , Trees {trees/1e6:.3f}m, Tree/Ha {trees/area} '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "out_val = loop_zonal_stats_update(input_zone_polygon=input_zone_pol,input_value_raster=ref_raster,fieldname='pred1',fn=np.nansum, is_update=False,bias=14.0, field_name='NAME_1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp = ogr.Open(input_zone_pol, update = 1)\n",
    "\n",
    "lyr = shp.GetLayer()\n",
    "\n",
    "lyr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split raster into blocks and save it as shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "EARTH_RADIUS = 6371000  # Radius in meters of Earth\n",
    "\n",
    "\n",
    "# Compute the shortest path curved distance between 2 points (lat1,lon1) and (lat2,lon2) using the Haversine formula.\n",
    "def haversine_distance(lon1, lat1, lon2, lat2):\n",
    "\n",
    "    a = math.sin(math.radians((lat2 - lat1) / 2.0)) ** 2 + math.cos(math.radians(lat1)) * math.cos(\n",
    "        math.radians(lat2)) * math.sin(math.radians((lon2 - lon1) / 2.0)) ** 2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    return EARTH_RADIUS * c\n",
    "\n",
    "def split_roi_to_rois(lon1_, lat1_, lon2_, lat2_, meters_split = 1500):\n",
    "\n",
    "    lon1, lat1, lon2, lat2 = min(lon1_, lon2_), min(lat1_,lat2_), max(lon1_, lon2_), max(lat1_, lat2_)\n",
    "\n",
    "    delta_lon_m = haversine_distance(lon1=lon1,lat1=lat1,lon2=lon2,lat2=lat1)\n",
    "    delta_lat_m = haversine_distance(lon1=lon1,lat1=lat1,lon2=lon1,lat2=lat2)\n",
    "    rois = []\n",
    "\n",
    "    N_lon, N_lat = map(lambda x: int(math.ceil(x / meters_split)), [delta_lon_m,delta_lat_m])\n",
    "\n",
    "    delta_lon, delta_lat = (lon2-lon1, lat2 - lat1)\n",
    "    for i in range(N_lat):\n",
    "        for j in range(N_lon):\n",
    "            ind = i * N_lon + j\n",
    "            rois.append({\"roi\": (\n",
    "                                lat1 + (delta_lat) * i / N_lat,\n",
    "                                lon1 + (delta_lon) * j / N_lon,\n",
    "                                lat1 + (delta_lat) * (i + 1) / N_lat,\n",
    "                                lon1 + (delta_lon) * (j + 1) / N_lon),\n",
    "                        \"name\": \"ROI{}\".format(ind + 1)})\n",
    "\n",
    "    return rois\n",
    "\n",
    "def to_bbox(roi_lon_lat):\n",
    "    if isinstance(roi_lon_lat, str):\n",
    "        roi_lon1, roi_lat1, roi_lon2, roi_lat2 = map(float, re.split(',', roi_lon_lat))\n",
    "    else:\n",
    "        roi_lon1, roi_lat1, roi_lon2, roi_lat2 = roi_lon_lat\n",
    "\n",
    "    geo_pts_ref = [(roi_lon1, roi_lat1), (roi_lon1, roi_lat2), (roi_lon2, roi_lat2), (roi_lon2, roi_lat1)]\n",
    "    return geo_pts_ref\n",
    "\n",
    "\n",
    "\n",
    "def convert_to_shp(points, is_overwrite=False):\n",
    "    if points.endswith('.kml'):\n",
    "        new_points=points.replace('.kml','.shp')\n",
    "        if not os.path.exists(new_points) or is_overwrite:\n",
    "            srcDS = gdal.OpenEx(points)\n",
    "            ds = gdal.VectorTranslate(new_points, srcDS, format='ESRI Shapefile')\n",
    "            ds = None\n",
    "            points = new_points\n",
    "    return points \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_raster = '/scratch/andresro/leon_work/sparse/inference/palmsarawak_simpleA20/T49MCV_preds_reg.tif'\n",
    "# ref_raster = '/scratch/andresro/leon_work/sparse/inference/palmcoco_kalimA_simpleA5/T49MCV_preds_reg.tif'\n",
    "# save_dir = '/scratch/andresro/leon_work/sparse/inference/palmcoco_kalimA_simpleA5'\n",
    "save_dir = '/scratch/andresro/leon_work/sparse/inference/palmsarawak_simpleA20/'\n",
    "ds = gdal.Open(ref_raster)\n",
    "\n",
    "geo_pts_ref = gp.get_lonlat(ds)\n",
    "lon1_, lat1_, lon2_, lat2_ = min([x[0] for x in geo_pts_ref]), min([x[1] for x in geo_pts_ref]),max([x[0] for x in geo_pts_ref]), max([x[1] for x in geo_pts_ref])\n",
    "\n",
    "roi_ = split_roi_to_rois(lon1_, lat1_, lon2_, lat2_,2000)\n",
    "print(len(roi_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.basename(ref_raster).replace('.tif','')\n",
    "kmlfile_name = f\"{save_dir}/{fname}_rois_{len(roi_)}.kml\"\n",
    "kml = simplekml.Kml()\n",
    "for roi in roi_:\n",
    "    lat1, lon1, lat2, lon2 = roi[\"roi\"]\n",
    "    # print roi\n",
    "\n",
    "    geo_pts_ref = to_bbox([lon1, lat1, lon2, lat2])\n",
    "    pol = kml.newpolygon(name=roi['name'])\n",
    "    pol.outerboundaryis = geo_pts_ref\n",
    "    pol.style.polystyle.color = simplekml.Color.changealphaint(100, simplekml.Color.white)\n",
    "\n",
    "kml.save(kmlfile_name)\n",
    "print(kmlfile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = convert_to_shp(kmlfile_name, is_overwrite=True)\n",
    "print(points)\n",
    "# drop_all_butName(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_zonal_stats_update(input_zone_polygon=points,input_value_raster=ref_raster,fieldname='pred_palm',fn=np.nansum, is_update=True, refband=1,bias=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmlfile_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gdal304]",
   "language": "python",
   "name": "conda-env-gdal304-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
