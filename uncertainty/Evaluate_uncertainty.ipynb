{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from osgeo import gdal, ogr, osr\n",
    "import os, sys\n",
    "import glob\n",
    "import simplekml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "sys.path.insert(0, os.getcwd())\n",
    "\n",
    "\n",
    "def no_output(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        sysout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, \"w\")\n",
    "        func(*args, **kwargs)\n",
    "        sys.stdout = sysout\n",
    "    return wrapper\n",
    "\n",
    "from utils.plots import plot_heatmap\n",
    "import utils.gdal_processing as gp\n",
    "from utils.gdal_processing import get_positive_area_folder, to_xy_box, rasterize_points_pos_neg_folder\n",
    "\n",
    "from utils.read_geoTiff import readHR\n",
    "# readHR = no_output(readHR)\n",
    "# get_positive_area_folder = no_output(get_positive_area_folder)\n",
    "# to_xy_box = no_output(to_xy_box)\n",
    "# rasterize_points_pos_neg_folder = no_output(rasterize_points_pos_neg_folder)\n",
    "\n",
    "            \n",
    "p2ha = lambda x: (x*10)**2 /100**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zonal_stats_old(FID, input_zone_polygon, input_value_raster, fn, is_return_numpoints = False, refband=1):\n",
    "\n",
    "    # Open data\n",
    "    raster = gdal.Open(input_value_raster)\n",
    "    shp = ogr.Open(input_zone_polygon)\n",
    "    lyr = shp.GetLayer()\n",
    "\n",
    "    # Get raster georeference info\n",
    "    transform = raster.GetGeoTransform()\n",
    "    xOrigin = transform[0]\n",
    "    yOrigin = transform[3]\n",
    "    pixelWidth = transform[1]\n",
    "    pixelHeight = transform[5]\n",
    "\n",
    "    # Reproject vector geometry to same projection as raster\n",
    "    sourceSR = lyr.GetSpatialRef()\n",
    "    targetSR = osr.SpatialReference()\n",
    "    targetSR.ImportFromWkt(raster.GetProjectionRef())\n",
    "    coordTrans = osr.CoordinateTransformation(sourceSR,targetSR)\n",
    "    feat = lyr.GetFeature(FID)\n",
    "    geom = feat.GetGeometryRef()\n",
    "    geom.Transform(coordTrans)\n",
    "\n",
    "    # Get extent of feat\n",
    "    geom = feat.GetGeometryRef()\n",
    "\n",
    "    if geom.GetGeometryName() == 'MULTIPOLYGON' :\n",
    "        count = 0\n",
    "        pointsX = []; pointsY = []\n",
    "        for polygon in geom:\n",
    "            geomInner = geom.GetGeometryRef(count)\n",
    "            ring = geomInner.GetGeometryRef(0)\n",
    "            numpoints = ring.GetPointCount()\n",
    "            for p in range(numpoints):\n",
    "                    lon, lat, z = ring.GetPoint(p)\n",
    "                    pointsX.append(lon)\n",
    "                    pointsY.append(lat)\n",
    "            count += 1\n",
    "    elif geom.GetGeometryName() == 'POLYGON':\n",
    "        ring = geom.GetGeometryRef(0)\n",
    "        numpoints = ring.GetPointCount()\n",
    "        pointsX = []; pointsY = []\n",
    "        for p in range(numpoints):\n",
    "                lon, lat, z = ring.GetPoint(p)\n",
    "                pointsX.append(lon)\n",
    "                pointsY.append(lat)\n",
    "    elif (geom.GetGeometryName() == 'LINESTRING'):\n",
    "        numpoints = geom.GetPointCount()\n",
    "        pointsX = []\n",
    "        pointsY = []\n",
    "        for p in range(numpoints):\n",
    "            lon, lat, z = geom.GetPoint(p)\n",
    "            pointsX.append(lon)\n",
    "            pointsY.append(lat)\n",
    "    else:\n",
    "        sys.exit(\"ERROR: Geometry needs to be either Polygon or Multipolygon\")\n",
    "\n",
    "    xmin = min(pointsX)\n",
    "    xmax = max(pointsX)\n",
    "    ymin = min(pointsY)\n",
    "    ymax = max(pointsY)\n",
    "\n",
    "    # Specify offset and rows and columns to read\n",
    "    xoff = int((xmin - xOrigin)/pixelWidth)\n",
    "    yoff = int((yOrigin - ymax)/pixelWidth)\n",
    "    if xoff < 0 or yoff < 0:\n",
    "        return np.nan\n",
    "    xcount = int((xmax - xmin)/pixelWidth)+1\n",
    "    ycount = int((ymax - ymin)/pixelWidth)+1\n",
    "\n",
    "    if is_return_numpoints:\n",
    "        # TODO check that all the points are inside the region of interest\n",
    "        return geom.GetPointCount()\n",
    "\n",
    "    # Create memory target raster\n",
    "    target_ds = gdal.GetDriverByName('MEM').Create('', xcount, ycount, 1, gdal.GDT_Byte)\n",
    "    target_ds.SetGeoTransform((\n",
    "        xmin, pixelWidth, 0,\n",
    "        ymax, 0, pixelHeight,\n",
    "    ))\n",
    "\n",
    "    # Create for target raster the same projection as for the value raster\n",
    "    raster_srs = osr.SpatialReference()\n",
    "    raster_srs.ImportFromWkt(raster.GetProjectionRef())\n",
    "    target_ds.SetProjection(raster_srs.ExportToWkt())\n",
    "\n",
    "    # Rasterize zone polygon to raster\n",
    "    gdal.RasterizeLayer(target_ds, [1], lyr, burn_values=[1])\n",
    "\n",
    "    # Read raster as arrays\n",
    "    banddataraster = raster.GetRasterBand(refband)\n",
    "    try:\n",
    "        dataraster = banddataraster.ReadAsArray(xoff, yoff, xcount, ycount).astype(np.float)\n",
    "    except AttributeError:\n",
    "        return np.nan\n",
    "    bandmask = target_ds.GetRasterBand(1)\n",
    "    datamask = bandmask.ReadAsArray(0, 0, xcount, ycount).astype(np.float)\n",
    "    print(datamask.mean())\n",
    "    clip = True\n",
    "    if clip:\n",
    "        dataraster = np.clip(dataraster,0.01,1e9)\n",
    "    if not np.any(datamask):\n",
    "        print('datamask empty')\n",
    "        return np.nan\n",
    "    # Mask zone of raster\n",
    "#     zoneraster = np.ma.masked_array(dataraster,  np.logical_not(datamask))\n",
    "    dataraster[np.logical_not(datamask)] = np.nan\n",
    "\n",
    "    # Calculate statistics of zonal raster\n",
    "    # return numpy.average(zoneraster),numpy.mean(zoneraster),numpy.median(zoneraster),numpy.std(zoneraster),numpy.var(zoneraster)\n",
    "    try:\n",
    "        return fn(dataraster)\n",
    "    except ValueError:\n",
    "        print('fix')\n",
    "        return np.nan\n",
    "    \n",
    "def loop_zonal_stats_update_old(input_zone_polygon, input_value_raster, fieldname, fn, is_update=True, refband=1, is_pos_only=False):\n",
    "\n",
    "    shp = ogr.Open(input_zone_polygon, update=1)\n",
    "    lyr = shp.GetLayer()\n",
    "    lyrdf =lyr.GetLayerDefn()\n",
    "\n",
    "    # TreeFieldName = 'TreePredAd1'\n",
    "    if is_update:\n",
    "        id_ = lyrdf.GetFieldIndex(fieldname)\n",
    "        if id_ == -1:\n",
    "            field_defn = ogr.FieldDefn(fieldname, ogr.OFTReal)\n",
    "            lyr.CreateField(field_defn)\n",
    "            id_ = lyrdf.GetFieldIndex(fieldname)\n",
    "        else:\n",
    "            print('Field {} already exists, may overwrite'.format(fieldname))\n",
    "    outVals = []\n",
    "    id_Name = lyrdf.GetFieldIndex('Name')\n",
    "    for FID in range(lyr.GetFeatureCount()):\n",
    "        feat = lyr.GetFeature(FID)\n",
    "        if feat is not None:\n",
    "            # compute sum\n",
    "            name_ = feat.GetField(id_Name)\n",
    "            if 'pos' in name_ or not is_pos_only:\n",
    "                meanValue = zonal_stats(FID, input_zone_polygon, input_value_raster, fn, refband=refband)\n",
    "                print(f' {meanValue:.2f} Trees in {name_}')\n",
    "\n",
    "            else:\n",
    "                meanValue = zonal_stats(FID, input_zone_polygon, input_value_raster, fn, is_return_numpoints=True, refband=refband)\n",
    "                print(f' {meanValue:.2f} Ref points in {name_}')\n",
    "            outVals.append(meanValue)\n",
    "            if np.isnan(meanValue):\n",
    "                print(meanValue,FID)\n",
    "            if is_update:\n",
    "                lyr.SetFeature(feat)\n",
    "                feat.SetField(id_,meanValue)\n",
    "                lyr.SetFeature(feat)\n",
    "    return np.sum(outVals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_zonal_stats_update(input_zone_polygon, input_value_raster, fieldname, fn, is_update=True, refband=1, is_pos_only=False,bias=1, field_name = 'Name'):\n",
    "\n",
    "    shp = ogr.Open(input_zone_polygon, update=1)\n",
    "    lyr = shp.GetLayer()\n",
    "    lyrdf =lyr.GetLayerDefn()\n",
    "\n",
    "    \n",
    "    id_ = lyrdf.GetFieldIndex(fieldname)\n",
    "    if id_ == -1:\n",
    "        field_defn = ogr.FieldDefn(fieldname, ogr.OFTReal)\n",
    "        lyr.CreateField(field_defn)\n",
    "        id_ = lyrdf.GetFieldIndex(fieldname)\n",
    "    else:\n",
    "        print('Field {} already exists, may overwrite'.format(fieldname))\n",
    "    outVals = []\n",
    "    id_Name = lyrdf.GetFieldIndex(field_name)\n",
    "    for FID in range(lyr.GetFeatureCount()):\n",
    "        feat = lyr.GetFeature(FID)\n",
    "        if feat is not None:\n",
    "            # compute sum\n",
    "            name_ = feat.GetField(id_Name)\n",
    "            meanValue = zonal_stats(FID, input_zone_polygon, input_value_raster, fn, refband=refband,bias=bias)\n",
    "#             print(f' {meanValue:.2f} Trees in {name_}')\n",
    "            outVals.append(meanValue)\n",
    "#             if np.isnan(meanValue):\n",
    "#                 print(name_,FID,'is all nan')\n",
    "            lyr.SetFeature(feat)\n",
    "            feat.SetField(id_,meanValue)\n",
    "            lyr.SetFeature(feat)\n",
    "    return np.sum(outVals)\n",
    "\n",
    "def zonal_stats(FID, input_zone_polygon, input_value_raster, fn, is_return_numpoints = False, refband=1, bias = 1.0):\n",
    "\n",
    "    # Open data\n",
    "    raster = gdal.Open(input_value_raster)\n",
    "    shp = ogr.Open(input_zone_polygon)\n",
    "    lyr = shp.GetLayer()\n",
    "\n",
    "    # Get raster georeference info\n",
    "    transform = raster.GetGeoTransform()\n",
    "    xOrigin = transform[0]\n",
    "    yOrigin = transform[3]\n",
    "    pixelWidth = transform[1]\n",
    "    pixelHeight = transform[5]\n",
    "\n",
    "    # Reproject vector geometry to same projection as raster\n",
    "    sourceSR = lyr.GetSpatialRef()\n",
    "    targetSR = osr.SpatialReference()\n",
    "    targetSR.ImportFromWkt(raster.GetProjectionRef())\n",
    "    coordTrans = osr.CoordinateTransformation(sourceSR,targetSR)\n",
    "    feat = lyr.GetFeature(FID)\n",
    "    geom = feat.GetGeometryRef()\n",
    "    geom.Transform(coordTrans)\n",
    "\n",
    "    # Get extent of feat\n",
    "    geom = feat.GetGeometryRef()\n",
    "    if (geom.GetGeometryName() == 'MULTIPOLYGON'):\n",
    "        count = 0\n",
    "        pointsX = []; pointsY = []\n",
    "        for polygon in geom:\n",
    "            geomInner = geom.GetGeometryRef(count)\n",
    "            ring = geomInner.GetGeometryRef(0)\n",
    "            numpoints = ring.GetPointCount()\n",
    "            for p in range(numpoints):\n",
    "                    lon, lat, z = ring.GetPoint(p)\n",
    "                    pointsX.append(lon)\n",
    "                    pointsY.append(lat)\n",
    "            count += 1\n",
    "    elif geom.GetGeometryName() == 'POLYGON':\n",
    "        ring = geom.GetGeometryRef(0)\n",
    "        numpoints = ring.GetPointCount()\n",
    "        pointsX = []; pointsY = []\n",
    "        for p in range(numpoints):\n",
    "                lon, lat, z = ring.GetPoint(p)\n",
    "                pointsX.append(lon)\n",
    "                pointsY.append(lat)\n",
    "    else:\n",
    "        sys.exit(\"ERROR: Geometry needs to be a Polygon\")\n",
    "    xmin = min(pointsX)\n",
    "    xmax = max(pointsX)\n",
    "    ymin = min(pointsY)\n",
    "    ymax = max(pointsY)\n",
    "\n",
    "    # Specify offset and rows and columns to read\n",
    "    xoff = int((xmin - xOrigin)/pixelWidth)\n",
    "    yoff = int((yOrigin - ymax)/pixelWidth)\n",
    "   \n",
    "    xcount = int((xmax - xmin)/pixelWidth)+1\n",
    "    ycount = int((ymax - ymin)/pixelWidth)+1\n",
    "\n",
    "\n",
    "    xoff = min(xoff,raster.RasterXSize -1)\n",
    "    xoff = max(xoff,1)\n",
    "    \n",
    "    xcount = min(xcount,raster.RasterXSize -1 - xoff)\n",
    "    ycount = min(ycount,raster.RasterYSize -1 - yoff)\n",
    "      \n",
    "\n",
    "    # Create memory target raster\n",
    "    target_ds = gdal.GetDriverByName('MEM').Create('', xcount, ycount, 1, gdal.GDT_Byte)\n",
    "    target_ds.SetGeoTransform((\n",
    "        xmin, pixelWidth, 0,\n",
    "        ymax, 0, pixelHeight,\n",
    "    ))\n",
    "\n",
    "    # Create for target raster the same projection as for the value raster\n",
    "    raster_srs = osr.SpatialReference()\n",
    "    raster_srs.ImportFromWkt(raster.GetProjectionRef())\n",
    "    target_ds.SetProjection(raster_srs.ExportToWkt())\n",
    "\n",
    "    # Rasterize zone polygon to raster\n",
    "    gdal.RasterizeLayer(target_ds, [1], lyr, burn_values=[1])\n",
    "\n",
    "    # Read raster as arrays\n",
    "    banddataraster = raster.GetRasterBand(refband)\n",
    "    try:\n",
    "        dataraster = banddataraster.ReadAsArray(xoff, yoff, xcount, ycount).astype(np.float)\n",
    "    except AttributeError:\n",
    "        print('dataraster wrong')\n",
    "#         print('geotransform',transform)\n",
    "        print(xoff,yoff,xcount,ycount)\n",
    "        print(raster.RasterXSize,raster.RasterYSize, 'xmax,ymax:',xoff+xcount,yoff+xcount)\n",
    "        return np.nan\n",
    "    \n",
    "    bandmask = target_ds.GetRasterBand(1)\n",
    "    datamask = bandmask.ReadAsArray(0, 0, xcount, ycount).astype(np.float)\n",
    "#     print(datamask.mean())\n",
    "    clip = True\n",
    "    if clip:\n",
    "#         dataraster = np.clip(dataraster,0.01,1e9)\n",
    "        dataraster[dataraster < 0.01] = np.nan\n",
    "    dataraster[dataraster == 99] = np.nan\n",
    "    \n",
    "    if not np.any(datamask):\n",
    "        print('datamask empty')\n",
    "        return np.nan\n",
    "    # Mask zone of raster\n",
    "#     zoneraster = np.ma.masked_array(dataraster,  np.logical_not(datamask))\n",
    "    dataraster[np.logical_not(datamask)] = np.nan\n",
    "    dataraster *=bias\n",
    "    # Calculate statistics of zonal raster\n",
    "    # return numpy.average(zoneraster),numpy.mean(zoneraster),numpy.median(zoneraster),numpy.std(zoneraster),numpy.var(zoneraster)\n",
    "    try:\n",
    "        return fn(dataraster)\n",
    "    except ValueError:\n",
    "        print('fix')\n",
    "        return np.nan\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj='palm'\n",
    "\n",
    "object_dict= {'palm':0,'coco':1}\n",
    "\n",
    "# ref_band = object_dict[obj]\n",
    "\n",
    "# points ='/home/pf/pfstud/andresro/tree_annotationsAug2019/annotations/Jan/palm/49MCV/Palm_Jan_1.kml'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2ha = lambda x: (x/10)**2\n",
    "def plot_preds(scale,raster,preds, tile, group,density = (0,3), std = None):\n",
    "    dens_min,dens_max = density\n",
    "    mask_out = np.isnan(raster) | np.isnan(preds)\n",
    "#         gt_count = raster[~mask_out].sum()\n",
    "    preds1 = preds.copy()\n",
    "    preds1[mask_out] = np.nan\n",
    "    raster1 = raster.copy()\n",
    "    raster1[mask_out] = np.nan\n",
    "    if std is not None:\n",
    "        std1 = std.copy()\n",
    "        std1[mask_out] = np.nan\n",
    "\n",
    "    print(p2ha(scale))\n",
    "    r1 = gp.block_reduce(raster1,(scale,scale),np.nansum)\n",
    "    p1 = gp.block_reduce(preds1,(scale,scale),np.nansum)\n",
    "    if std is not None:\n",
    "        s1 = gp.block_reduce(std1,(scale,scale),np.nanmean)\n",
    "    diff = p1  - r1\n",
    "    diff1 = (p1 - r1 )/ r1\n",
    "    diff1[np.logical_and(r1 == 0, p1 == 0) ] = 0\n",
    "    diff1[np.logical_and(r1 == 0, p1 > 0) ] = np.nan\n",
    "\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    n_col = 3 if std is None else 4    \n",
    "    gs = gridspec.GridSpec(nrows=1,ncols=n_col,left=0.02, bottom=0.06, right=0.95, top=0.94, wspace=0.1)\n",
    "\n",
    "    txt = f' {tile} {group} {p2ha(scale)}ha'\n",
    "    \n",
    "    # GT\n",
    "    ax = plt.subplot(gs[0])\n",
    "    im = ax.imshow(raster,vmin=dens_min,vmax=dens_max)\n",
    "    \n",
    "    cbar = fig.colorbar(im,ax=ax,orientation='horizontal')\n",
    "    cbar.ax.set_xlabel(f'Trees/ {p2ha(1):.2f}ha blocks')\n",
    "    ax.set_title(f'Trees GT {np.nansum(raster1):.2f} ({np.nanmax(raster):.2f})')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(f' {preds1.shape[0]/100:.2f}km')\n",
    "    ax.set_ylabel(f' {preds1.shape[1]/100:.2f}km')\n",
    "\n",
    "    # PREDS\n",
    "    ax = plt.subplot(gs[1])\n",
    "    im = ax.imshow(preds,vmin=dens_min,vmax=dens_max)\n",
    "    cbar = fig.colorbar(im,ax=ax,orientation='horizontal')\n",
    "    cbar.ax.set_xlabel(f'Trees/ {p2ha(1):.2f}ha blocks')\n",
    "    ax.set_title(f'Trees Pred {np.nansum(preds1):.2f} ({np.nanmax(preds):.2f})')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(f' {preds1.shape[0]/100:.2f}km \\n\\n'+txt)\n",
    "    ax.set_ylabel(f' {preds1.shape[1]/100:.2f}km')\n",
    "\n",
    "    # DIFSS\n",
    "    ax = plt.subplot(gs[2])\n",
    "    lim_ = dens_max * ((scale/2)**2)\n",
    "    im = ax.imshow(diff,cmap = 'bwr', vmin = -lim_,vmax=lim_ ) #,vmin=-dens_max*scale*3,vmax=dens_max*scale*3)\n",
    "    cbar = fig.colorbar(im,ax=ax,orientation='horizontal')\n",
    "    cbar.ax.set_xlabel(f'Trees/ {p2ha(scale)}ha blocks')\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax.set_title(f'Error per {p2ha(scale)}ha blocks')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    \n",
    "\n",
    "        # STD\n",
    "    if std is not None:\n",
    "        ax = plt.subplot(gs[3])\n",
    "        im = ax.imshow(std ,vmin=0,vmax=1, cmap='inferno')\n",
    "        cbar = fig.colorbar(im,ax=ax,orientation='horizontal')\n",
    "        cbar.ax.set_xlabel(f'Trees/ {p2ha(1):.2f}ha blocks')\n",
    "        ax.set_title(f'STD  mean (max) {np.nanmean(std):.2f} ({np.nanmax(std):.2f})')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xlabel(f' {preds1.shape[0]/100:.2f}km \\n\\n'+txt)\n",
    "        ax.set_ylabel(f' {preds1.shape[1]/100:.2f}km')\n",
    "\n",
    "    # Scatter\n",
    "    zeros_ = np.logical_and(p1== 0,r1==0).ravel()\n",
    "    ds = pd.DataFrame({'GT':r1.ravel(),'Pred':p1.ravel()})\n",
    "    if std is not None:\n",
    "        ds['std'] = s1.ravel()\n",
    "    return ds\n",
    "\n",
    "#@no_output\n",
    "def plot_counts(folder_inference, tile, folder_annotations, group='group1', preds_axis=0, sq_kernel=2, scale=10):\n",
    "    ds_out = pd.DataFrame(columns=['GT','Pred'])\n",
    "    \n",
    "    if not isinstance(folder_annotations,list):\n",
    "        ref_folders = glob.glob(f'{folder_annotations}/{tile}/{group}')\n",
    "        if not ref_folders:\n",
    "            print(f'no folders in {folder_annotations}/{tile}/{group}')\n",
    "            return ds_out\n",
    "    else:\n",
    "        ref_folders = [x for x in folder_annotations if tile in x]\n",
    "\n",
    "    is_aut_gt = False\n",
    "    for ref_folder in ref_folders:\n",
    "        group = ref_folder.split('/')[-1]\n",
    "        print(ref_folder, group)\n",
    "        ref_raster = glob.glob(f'{folder_inference}/{tile}*_preds_reg*.tif')\n",
    "        if len(ref_raster) == 0:\n",
    "            print(f' no files found in {folder_inference}/{tile}*_preds_reg*.tif skipping...')\n",
    "        else:\n",
    "            ref_raster = ref_raster[0]\n",
    "\n",
    "\n",
    "            ds = gdal.Open(ref_raster)\n",
    "            roi_ = get_positive_area_folder(ref_folder)\n",
    "            lims = to_xy_box(roi_, ds, enlarge=10)\n",
    "\n",
    "            raster = rasterize_points_pos_neg_folder(folder=ref_folder,refDataset=ref_raster,lims=lims,lims_with_labels=lims,sq_kernel=sq_kernel)\n",
    "            raster[raster == -1] = np.nan\n",
    "\n",
    "            preds = readHR(data_file=ref_raster,roi_lon_lat=roi_,scale=10, as_float=False, is_assert_blank=False)\n",
    "            \n",
    "            if preds.shape[-1] == 2:\n",
    "                preds = preds[...,preds_axis]\n",
    "            preds[preds <0] = 0\n",
    "            preds[preds==99] = np.nan\n",
    "        #     preds = np.clip(preds*1.3,0,2.5)\n",
    "\n",
    "            ref_raster_sem = ref_raster.replace('reg.tif','semA.tif')\n",
    "\n",
    "            if os.path.isfile(ref_raster_sem):\n",
    "                preds_sem = readHR(data_file=ref_raster.replace('reg.tif','semA.tif'),roi_lon_lat=roi_,scale=10, as_float=False, is_assert_blank=False)\n",
    "            else:\n",
    "                preds_sem = preds > 0.5\n",
    "                \n",
    "            ref_raster_std = glob.glob(f'{folder_inference}/std/{tile}*preds_reg_0_std_0.tif')\n",
    "            \n",
    "            if len(ref_raster_std) > 0:\n",
    "                ref_raster_std = ref_raster_std[0]\n",
    "                print('adding std')\n",
    "                preds_std = readHR(data_file=ref_raster_std,roi_lon_lat=roi_,scale=10, as_float=False, is_assert_blank=False)\n",
    "            else:\n",
    "                preds_std = None\n",
    "                print(f'{folder_inference}/std/{tile}*preds_reg_0_std_0.tif')\n",
    "             \n",
    "            ds = plot_preds(scale,raster,preds, tile, group, std=preds_std)\n",
    "            ds_out = ds_out.append(ds)\n",
    "\n",
    "        return ds_out\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Palm 4748 - Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder_inference = '/home/pf/pfstaff/projects/andresro/sparse/inference_leon/borneo_simpleA9_mc10'\n",
    "#folder_inference = '/scratch/andresro/leon_work/sparse/inference/cocopreactive_simpleA9_soft_mc5'\n",
    "folder_inference = '/scratch/andresro/leon_work/sparse/inference/palm4748a_simpleA9_soft_mc5'\n",
    "folder_annotations = [\n",
    "   '/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations/T48MTD/palm_group2_Bischel',\n",
    "       '/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations/T47NNC/palm_group3_Brunner',\n",
    "       '/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations/T48MVV/palm_group1_julia',\n",
    "       '/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations/T47NLE/palm_group2_hanlon',\n",
    "       '/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations/T47NNA/palm_group3_Julia',\n",
    "       '/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations/T48NTJ/palm_group1',\n",
    "       '/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations/T47NQE/palm_group3',\n",
    "       '/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations/T48MVB/palm_group2_Bischel',\n",
    "       '/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations/T48NUG/palm_group2',\n",
    "       '/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations/T46NGL/palm_group3_janmathias'\n",
    "]\n",
    "\n",
    "scale=20\n",
    "ds_out = pd.DataFrame(columns=['GT','Pred'])\n",
    "\n",
    "tilenames = 'T48MVV T48NUG T47NNC T47NNA T47NQE T46NGL T47NLE T48MTD T48NTJ T48MVB'.split(' ')\n",
    "#tilenames = ['T48MTD']\n",
    "for tile in tilenames:\n",
    "        \n",
    "    ds_ = plot_counts(folder_inference=folder_inference,\n",
    "                tile=tile,\n",
    "                folder_annotations=folder_annotations,\n",
    "                group=None, scale=scale)\n",
    "    if ds_ is not None:\n",
    "        ds_out = ds_out.append(ds_,ignore_index=True)\n",
    "    else:\n",
    "        print('error in tile',tile)\n",
    "\n",
    "ds_out['resid'] = np.abs(ds_out['GT'] - ds_out['Pred'])\n",
    "ds_drop = ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_ = np.logical_and(ds_drop.GT== 0,ds_drop.Pred==0)\n",
    "ds = ds_drop[~zeros_].copy()\n",
    "\n",
    "# ds['Pred'] = ds.Pred*1.2\n",
    "\n",
    "g = sns.jointplot(x='Pred',y='GT',data=ds, cmap=\"Reds\",\n",
    "#                   kind=\"hex\",\n",
    "                 ) #, clip=(dens_min,dens_max))\n",
    "\n",
    "lims = (0,np.nanmax(ds.GT))\n",
    "g.ax_marg_x.set_xlim(lims)\n",
    "g.ax_marg_y.set_ylim(lims)\n",
    "\n",
    "# lims = [max(x0, y0), min(x1, y1)]\n",
    "g.ax_joint.plot(lims, lims, ':k')    \n",
    "plt.title(f' MAE {np.nanmean(np.abs(ds.Pred -ds.GT))/p2ha(scale):.2f} Trees/ha in {p2ha(scale)}ha Blocks  \\n ' \\\n",
    "          f'total trees GT:{np.nansum(ds.GT):.2f} Pred:{np.nansum(ds.Pred):.2f} ({100*(np.nansum(ds.Pred)-np.nansum(ds.GT))/np.nansum(ds.GT):.2f}%) \\n',x=-0.1,y=0.5, fontsize = 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bins = np.linspace(0,ds['resid'].max(), num=50)\n",
    "#bins = np.percentile(ds['resid'],np.arange(0,100))\n",
    "bins = np.percentile(ds['resid'],np.linspace(5,100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_std = []\n",
    "for b_ in bins:\n",
    "    a = ds['std'][ds['resid']<=b_].mean()\n",
    "    avg_std.append(a)\n",
    "avg_std = np.array(avg_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bins/bins.max(), avg_std,'o-')\n",
    "\n",
    "plt.ylabel('std')\n",
    "plt.xlabel('recall based on resid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bins = np.linspace(0,ds['resid'].max(), num=50)\n",
    "#bins = np.percentile(ds['resid'],np.arange(0,100))\n",
    "bins = np.percentile(ds['std'],np.linspace(5,100,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_resid = []\n",
    "for b_ in bins:\n",
    "    a = ds['resid'][ds['std']<=b_].mean()\n",
    "    avg_resid.append(a)\n",
    "avg_resid = np.array(avg_resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_drop = bins/bins.max()\n",
    "avg_resid_drop = avg_resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bins/bins.max(), avg_resid,'o-')\n",
    "# plt.plot(bins, avg_resid,'o-')\n",
    "\n",
    "plt.ylabel('$|y - \\hat{y}|$')\n",
    "plt.xlabel('recall based on std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['resid'].plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['std'].plot.hist(bins=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.jointplot('resid',y='std',data=ds, cmap=\"Reds\",\n",
    "           kind=\"hex\", \n",
    "                  joint_kws={\n",
    "                      'gridsize':30,\n",
    "                  #           'bins':10\n",
    "                  },\n",
    "                 ) #, clip=(dens_min,dens_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Palm 4748 - Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder_inference = '/home/pf/pfstaff/projects/andresro/sparse/inference_leon/borneo_simpleA9_mc10'\n",
    "#folder_inference = '/scratch/andresro/leon_work/sparse/inference/cocopreactive_simpleA9_soft_mc5'\n",
    "folder_inference = '/scratch/andresro/leon_work/sparse/inference/palm4748a_simpleA9_soft_ens5/'\n",
    "folder_annotations = [\n",
    "   '/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations/T48MTD/palm_group2_Bischel',\n",
    "       '/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations/T47NNC/palm_group3_Brunner',\n",
    "       '/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations/T48MVV/palm_group1_julia',\n",
    "       '/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations/T47NLE/palm_group2_hanlon',\n",
    "       '/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations/T47NNA/palm_group3_Julia',\n",
    "       '/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations/T48NTJ/palm_group1',\n",
    "       '/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations/T47NQE/palm_group3',\n",
    "       '/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations/T48MVB/palm_group2_Bischel',\n",
    "       '/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations/T48NUG/palm_group2',\n",
    "       '/home/pf/pfstaff/projects/andresro/barry_palm/data/labels/manual_annotations/T46NGL/palm_group3_janmathias'\n",
    "]\n",
    "\n",
    "scale=20\n",
    "ds_out = pd.DataFrame(columns=['GT','Pred'])\n",
    "\n",
    "tilenames = 'T48MVV T48NUG T47NNC T47NNA T47NQE T46NGL T47NLE T48MTD T48NTJ T48MVB'.split(' ')\n",
    "#tilenames = ['T48MTD']\n",
    "for tile in tilenames:\n",
    "        \n",
    "    ds_ = plot_counts(folder_inference=folder_inference,\n",
    "                tile=tile,\n",
    "                folder_annotations=folder_annotations,\n",
    "                group=None, scale=scale)\n",
    "    if ds_ is not None:\n",
    "        ds_out = ds_out.append(ds_,ignore_index=True)\n",
    "    else:\n",
    "        print('error in tile',tile)\n",
    "        \n",
    "ds_out['resid'] = np.abs(ds_out['GT'] - ds_out['Pred'])\n",
    "ds_ens = ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_ = np.logical_or(ds_ens.GT== 0,ds_ens.Pred==0)\n",
    "ds = ds_ens[~zeros_].copy()\n",
    "\n",
    "ds['Pred'] = ds.Pred\n",
    "\n",
    "g = sns.jointplot(x='Pred',y='GT',data=ds, cmap=\"Reds\",\n",
    "#                   kind=\"hex\",\n",
    "                 ) #, clip=(dens_min,dens_max))\n",
    "\n",
    "lims = (0,np.nanmax(ds.GT))\n",
    "g.ax_marg_x.set_xlim(lims)\n",
    "g.ax_marg_y.set_ylim(lims)\n",
    "\n",
    "# lims = [max(x0, y0), min(x1, y1)]\n",
    "g.ax_joint.plot(lims, lims, ':k')    \n",
    "plt.title(f' MAE {np.nanmean(np.abs(ds.Pred -ds.GT))/p2ha(scale):.2f} Trees/ha in {p2ha(scale)}ha Blocks  \\n ' \\\n",
    "          f'total trees GT:{np.nansum(ds.GT):.2f} Pred:{np.nansum(ds.Pred):.2f} ({100*(np.nansum(ds.Pred)-np.nansum(ds.GT))/np.nansum(ds.GT):.2f}%) \\n',x=-0.1,y=0.5, fontsize = 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#bins = np.linspace(0,ds['resid'].max(), num=50)\n",
    "#bins = np.percentile(ds['resid'],np.arange(0,100))\n",
    "bins = np.percentile(ds['resid'],np.linspace(5,100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_std = []\n",
    "for b_ in bins:\n",
    "    a = ds['std'][ds['resid']<=b_].mean()\n",
    "    avg_std.append(a)\n",
    "avg_std = np.array(avg_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bins/bins.max(), avg_std,'o-')\n",
    "\n",
    "plt.ylabel('std')\n",
    "plt.xlabel('recall based on resid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bins = np.linspace(0,ds['resid'].max(), num=50)\n",
    "#bins = np.percentile(ds['resid'],np.arange(0,100))\n",
    "bins = np.percentile(ds['std'],np.linspace(5,100,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_resid = []\n",
    "for b_ in bins:\n",
    "    a = ds['resid'][ds['std']<=b_].mean()\n",
    "    avg_resid.append(a)\n",
    "avg_resid = np.array(avg_resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_ens = bins/bins.max()\n",
    "avg_resid_ens = avg_resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bins/bins.max(), avg_resid,'o-')\n",
    "# plt.plot(bins, avg_resid,'o-')\n",
    "\n",
    "plt.ylabel('$|y - \\hat{y}|$')\n",
    "plt.xlabel('recall based on std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['resid'].plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['std'].plot.hist(bins=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "g = sns.jointplot('resid',y='std',data=ds, cmap=\"Reds\",\n",
    "#                   kind=\"hex\",\n",
    "                 ) #, clip=(dens_min,dens_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/scratch2/Dropbox/Dropbox/Apps/Overleaf/activelearning_remotesensing/figures/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1)\n",
    "plt.title('Uncertainty Calibration')\n",
    "plt.plot(recall_drop, avg_resid_drop,'o-', label='MC-dropout')\n",
    "plt.plot(recall_ens, avg_resid_ens,'o-', label='Ensemble')\n",
    "\n",
    "plt.ylabel('$|y - \\hat{y}|$')\n",
    "plt.xlabel('recall')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# fig.savefig(save_path+'uncertainty_calibration.pdf',) # bbox_extra_artists=(lgd,), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = np.linspace(0.05,1,50)\n",
    "\n",
    "fig = plt.figure(1)\n",
    "plt.title('Uncertainty Calibration')\n",
    "plt.plot(recall, avg_resid_drop,'o-', label='MC-dropout')\n",
    "plt.plot(recall, avg_resid_ens,'o-', label='Ensemble')\n",
    "\n",
    "plt.ylabel('$|y - \\hat{y}|$')\n",
    "plt.xlabel('recall')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "#fig.savefig(save_path+'uncertainty_calibration.pdf',) # bbox_extra_artists=(lgd,), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gdal233]",
   "language": "python",
   "name": "conda-env-gdal233-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
